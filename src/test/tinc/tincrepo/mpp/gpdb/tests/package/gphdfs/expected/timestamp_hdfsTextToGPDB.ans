-- start_ignore
-- end_ignore
\echo --start_ignore
--start_ignore
drop external table timestamp_heap;
DROP EXTERNAL TABLE
drop external table timestamp_readhdfs_mapreduce;
psql:/path/sql_file:1: ERROR:  table "timestamp_readhdfs_mapreduce" does not exist
drop external table timestamp_readhdfs_mapred;
psql:/path/sql_file:1: ERROR:  table "timestamp_readhdfs_mapred" does not exist
drop external table timestamp_readhdfs_mapreduce_blockcomp;
DROP EXTERNAL TABLE
drop external table timestamp_readhdfs_mapreduce_recordcomp;
DROP EXTERNAL TABLE
drop external table timestamp_readhdfs_mapred_blockcomp;
DROP EXTERNAL TABLE
drop external table timestamp_readhdfs_mapred_recordcomp;
DROP EXTERNAL TABLE
\echo --end_ignore
--end_ignore
create readable external table timestamp_heap(datatype_timestamp varchar,xcount_timestamp bigint, col1_timestamp timestamp,col2_timestamp timestamp, col3_timestamp timestamp, nullcol_timestamp timestamp) location ('gpfdist://sdw1.dh.greenplum.com:8080/timestamp.txt')format 'TEXT';
CREATE EXTERNAL TABLE
\!export HADOOP_HOME=/usr/lib/gphd/hadoop/; source /data/gpadmin/gpdb/greenplum/lib/hadoop/hadoop_env.sh; java -cp .:$CLASSPATH:/data/gpadmin/gpdb/greenplum/lib/hadoop/gphd-2.0.2-gnet-1.2.0.0.jar:/data/gpadmin/workspace/tincrepo/main/mpp/gpdb/tests/package/gphdfs/maptest.jar -Dhdfshost=sdw1.dh.greenplum.com -Ddatanodeport=8020 -Djobtrackerhost=sdw1.dh.greenplum.com -Djobtrackerport=8020  -DcompressionType=none javaclasses/TestHadoopIntegration mapreduce Mapreduce_mapper_TextIn /plaintext/timestamp.txt /mapreduce/timestamp 
14/08/15 14:00:26 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 14:00:27 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/08/15 14:00:28 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
14/08/15 14:00:29 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 853 for gpadmin on 192.168.2.100:8020
14/08/15 14:00:29 INFO security.TokenCache: Got dt for hdfs://sdw1.dh.greenplum.com:8020; Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 853 for gpadmin)
14/08/15 14:00:29 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/08/15 14:00:29 INFO input.FileInputFormat: Total input paths to process : 1
14/08/15 14:00:30 INFO mapreduce.JobSubmitter: number of splits:1
14/08/15 14:00:30 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/08/15 14:00:30 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/08/15 14:00:30 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 14:00:30 INFO Configuration.deprecation: mapred.job.reduce.memory.mb is deprecated. Instead, use mapreduce.reduce.memory.mb
14/08/15 14:00:30 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/08/15 14:00:30 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/08/15 14:00:30 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/08/15 14:00:30 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
14/08/15 14:00:30 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/08/15 14:00:30 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/08/15 14:00:30 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/08/15 14:00:30 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/08/15 14:00:30 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/08/15 14:00:30 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/08/15 14:00:30 INFO Configuration.deprecation: mapred.job.map.memory.mb is deprecated. Instead, use mapreduce.map.memory.mb
14/08/15 14:00:30 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/08/15 14:00:30 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1408131000469_0117
14/08/15 14:00:30 INFO mapreduce.JobSubmitter: Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 853 for gpadmin)
14/08/15 14:00:30 INFO impl.YarnClientImpl: Submitted application application_1408131000469_0117 to ResourceManager at /0.0.0.0:8032
14/08/15 14:00:30 INFO mapreduce.Job: The url to track the job: http://0.0.0.0:9999/proxy/application_1408131000469_0117/
14/08/15 14:00:30 INFO mapreduce.Job: Running job: job_1408131000469_0117
14/08/15 14:00:38 INFO mapreduce.Job: Job job_1408131000469_0117 running in uber mode : false
14/08/15 14:00:38 INFO mapreduce.Job:  map 0% reduce 0%
14/08/15 14:00:44 INFO mapreduce.Job:  map 100% reduce 0%
14/08/15 14:00:50 INFO mapreduce.Job:  map 100% reduce 100%
14/08/15 14:00:50 INFO mapreduce.Job: Job job_1408131000469_0117 completed successfully
14/08/15 14:00:50 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=864014
		FILE: Number of bytes written=1897509
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=602634
		HDFS: Number of bytes written=897434
		HDFS: Number of read operations=6
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=10662
		Total time spent by all reduces in occupied slots (ms)=11058
	Map-Reduce Framework
		Map input records=5000
		Map output records=5000
		Map output bytes=849008
		Map output materialized bytes=864014
		Input split bytes=122
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=864014
		Reduce input records=5000
		Reduce output records=5000
		Spilled Records=10000
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=46
		CPU time spent (ms)=3070
		Physical memory (bytes) snapshot=1013755904
		Virtual memory (bytes) snapshot=6098403328
		Total committed heap usage (bytes)=1373372416
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=602512
	File Output Format Counters 
		Bytes Written=897434
create readable external table timestamp_readhdfs_mapreduce(like timestamp_heap) location ('gphdfs://sdw1.dh.greenplum.com:8020/mapreduce/timestamp')format 'custom' (formatter='gphdfs_import');
CREATE EXTERNAL TABLE
\!export HADOOP_HOME=/usr/lib/gphd/hadoop/; source /data/gpadmin/gpdb/greenplum/lib/hadoop/hadoop_env.sh; java -cp .:$CLASSPATH:/data/gpadmin/gpdb/greenplum/lib/hadoop/gphd-2.0.2-gnet-1.2.0.0.jar:/data/gpadmin/workspace/tincrepo/main/mpp/gpdb/tests/package/gphdfs/maptest.jar -Dhdfshost=sdw1.dh.greenplum.com -Ddatanodeport=8020 -Djobtrackerhost=sdw1.dh.greenplum.com -Djobtrackerport=8020  -DcompressionType=none javaclasses/TestHadoopIntegration mapred Mapred_mapper_TextIn /plaintext/timestamp.txt /mapred/timestamp
14/08/15 14:00:52 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 14:00:52 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
14/08/15 14:00:52 INFO Configuration.deprecation: mapred.job.map.memory.mb is deprecated. Instead, use mapreduce.map.memory.mb
14/08/15 14:00:52 INFO Configuration.deprecation: mapred.job.reduce.memory.mb is deprecated. Instead, use mapreduce.reduce.memory.mb
14/08/15 14:00:52 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/08/15 14:00:53 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
14/08/15 14:00:53 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
14/08/15 14:00:53 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 854 for gpadmin on 192.168.2.100:8020
14/08/15 14:00:53 INFO security.TokenCache: Got dt for hdfs://sdw1.dh.greenplum.com:8020; Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 854 for gpadmin)
14/08/15 14:00:54 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/08/15 14:00:54 INFO mapred.FileInputFormat: Total input paths to process : 1
14/08/15 14:00:54 INFO mapreduce.JobSubmitter: number of splits:2
14/08/15 14:00:54 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/08/15 14:00:54 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/08/15 14:00:54 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 14:00:54 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/08/15 14:00:54 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/08/15 14:00:54 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
14/08/15 14:00:54 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/08/15 14:00:54 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/08/15 14:00:54 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/08/15 14:00:54 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/08/15 14:00:54 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/08/15 14:00:54 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1408131000469_0118
14/08/15 14:00:54 INFO mapreduce.JobSubmitter: Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 854 for gpadmin)
14/08/15 14:00:54 INFO impl.YarnClientImpl: Submitted application application_1408131000469_0118 to ResourceManager at /0.0.0.0:8032
14/08/15 14:00:54 INFO mapreduce.Job: The url to track the job: http://0.0.0.0:9999/proxy/application_1408131000469_0118/
14/08/15 14:00:54 INFO mapreduce.Job: Running job: job_1408131000469_0118
14/08/15 14:01:05 INFO mapreduce.Job: Job job_1408131000469_0118 running in uber mode : false
14/08/15 14:01:05 INFO mapreduce.Job:  map 0% reduce 0%
14/08/15 14:01:11 INFO mapreduce.Job:  map 100% reduce 0%
14/08/15 14:01:17 INFO mapreduce.Job:  map 100% reduce 100%
14/08/15 14:01:17 INFO mapreduce.Job: Job job_1408131000469_0118 completed successfully
14/08/15 14:01:17 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=864014
		FILE: Number of bytes written=1981741
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=604578
		HDFS: Number of bytes written=897434
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=21528
		Total time spent by all reduces in occupied slots (ms)=11148
	Map-Reduce Framework
		Map input records=5000
		Map output records=5000
		Map output bytes=849008
		Map output materialized bytes=864020
		Input split bytes=218
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=864020
		Reduce input records=5000
		Reduce output records=5000
		Spilled Records=10000
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=64
		CPU time spent (ms)=4150
		Physical memory (bytes) snapshot=1792184320
		Virtual memory (bytes) snapshot=8288530432
		Total committed heap usage (bytes)=2242641920
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=604360
	File Output Format Counters 
		Bytes Written=897434
create readable external table timestamp_readhdfs_mapred(like timestamp_readhdfs_mapreduce) location ('gphdfs://sdw1.dh.greenplum.com:8020/mapred/timestamp')format 'custom' (formatter='gphdfs_import');
CREATE EXTERNAL TABLE
select count(*) from timestamp_readhdfs_mapreduce;
 count 
-------
  5000
(1 row)

select count(*) from timestamp_readhdfs_mapred;
 count 
-------
  5000
(1 row)

select * from timestamp_readhdfs_mapreduce order by xcount_timestamp limit 10;
           datatype_timestamp            | xcount_timestamp |   col1_timestamp    |   col2_timestamp    |   col3_timestamp    | nullcol_timestamp 
-----------------------------------------+------------------+---------------------+---------------------+---------------------+-------------------
 timestamp,timestamp,timestamp,timestamp |                0 | 0001-01-01 00:00:00 | 0001-01-01 00:00:00 | 0001-01-01 00:00:00 | 
 timestamp,timestamp,timestamp,timestamp |                1 | 0002-02-02 01:01:01 | 0002-02-02 01:01:01 | 0002-01-02 01:01:01 | 
 timestamp,timestamp,timestamp,timestamp |                2 | 0003-03-03 02:02:02 | 0003-03-03 02:02:02 | 0003-02-03 02:02:02 | 
 timestamp,timestamp,timestamp,timestamp |                3 | 0004-04-04 03:03:03 | 0004-04-04 03:03:03 | 0004-02-04 03:03:03 | 
 timestamp,timestamp,timestamp,timestamp |                4 | 0005-05-05 04:04:04 | 0005-05-05 04:04:04 | 0005-03-05 04:04:04 | 
 timestamp,timestamp,timestamp,timestamp |                5 | 0006-06-06 05:05:05 | 0006-06-06 05:05:05 | 0006-03-06 05:05:05 | 
 timestamp,timestamp,timestamp,timestamp |                6 | 0007-07-07 06:06:06 | 0007-07-07 06:06:06 | 0007-04-07 06:06:06 | 
 timestamp,timestamp,timestamp,timestamp |                7 | 0008-08-08 07:07:07 | 0008-08-08 07:07:07 | 0008-04-08 07:07:07 | 
 timestamp,timestamp,timestamp,timestamp |                8 | 0009-09-09 08:08:08 | 0009-09-09 08:08:08 | 0009-05-09 08:08:08 | 
 timestamp,timestamp,timestamp,timestamp |                9 | 0010-10-10 09:09:09 | 0010-10-10 09:09:09 | 0010-05-10 09:09:09 | 
(10 rows)

select * from timestamp_readhdfs_mapred order by xcount_timestamp limit 10;
           datatype_timestamp            | xcount_timestamp |   col1_timestamp    |   col2_timestamp    |   col3_timestamp    | nullcol_timestamp 
-----------------------------------------+------------------+---------------------+---------------------+---------------------+-------------------
 timestamp,timestamp,timestamp,timestamp |                0 | 0001-01-01 00:00:00 | 0001-01-01 00:00:00 | 0001-01-01 00:00:00 | 
 timestamp,timestamp,timestamp,timestamp |                1 | 0002-02-02 01:01:01 | 0002-02-02 01:01:01 | 0002-01-02 01:01:01 | 
 timestamp,timestamp,timestamp,timestamp |                2 | 0003-03-03 02:02:02 | 0003-03-03 02:02:02 | 0003-02-03 02:02:02 | 
 timestamp,timestamp,timestamp,timestamp |                3 | 0004-04-04 03:03:03 | 0004-04-04 03:03:03 | 0004-02-04 03:03:03 | 
 timestamp,timestamp,timestamp,timestamp |                4 | 0005-05-05 04:04:04 | 0005-05-05 04:04:04 | 0005-03-05 04:04:04 | 
 timestamp,timestamp,timestamp,timestamp |                5 | 0006-06-06 05:05:05 | 0006-06-06 05:05:05 | 0006-03-06 05:05:05 | 
 timestamp,timestamp,timestamp,timestamp |                6 | 0007-07-07 06:06:06 | 0007-07-07 06:06:06 | 0007-04-07 06:06:06 | 
 timestamp,timestamp,timestamp,timestamp |                7 | 0008-08-08 07:07:07 | 0008-08-08 07:07:07 | 0008-04-08 07:07:07 | 
 timestamp,timestamp,timestamp,timestamp |                8 | 0009-09-09 08:08:08 | 0009-09-09 08:08:08 | 0009-05-09 08:08:08 | 
 timestamp,timestamp,timestamp,timestamp |                9 | 0010-10-10 09:09:09 | 0010-10-10 09:09:09 | 0010-05-10 09:09:09 | 
(10 rows)

(select * from timestamp_readhdfs_mapreduce except select * from timestamp_readhdfs_mapred) union (select * from timestamp_readhdfs_mapred except select * from timestamp_readhdfs_mapreduce);
 datatype_timestamp | xcount_timestamp | col1_timestamp | col2_timestamp | col3_timestamp | nullcol_timestamp 
--------------------+------------------+----------------+----------------+----------------+-------------------
(0 rows)

\!export HADOOP_HOME=/usr/lib/gphd/hadoop/; source /data/gpadmin/gpdb/greenplum/lib/hadoop/hadoop_env.sh; java -cp .:$CLASSPATH:/data/gpadmin/gpdb/greenplum/lib/hadoop/gphd-2.0.2-gnet-1.2.0.0.jar:/data/gpadmin/workspace/tincrepo/main/mpp/gpdb/tests/package/gphdfs/maptest.jar -Dhdfshost=sdw1.dh.greenplum.com -Ddatanodeport=8020 -Djobtrackerhost=sdw1.dh.greenplum.com -Djobtrackerport=8020  -DcompressionType=block javaclasses/TestHadoopIntegration mapreduce Mapreduce_mapper_TextIn /plaintext/timestamp.txt /mapreduce/blockcomp/timestamp
14/08/15 14:01:41 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 14:01:41 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/08/15 14:01:42 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
14/08/15 14:01:42 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 871 for gpadmin on 192.168.2.100:8020
14/08/15 14:01:42 INFO security.TokenCache: Got dt for hdfs://sdw1.dh.greenplum.com:8020; Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 871 for gpadmin)
14/08/15 14:01:43 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/08/15 14:01:43 INFO input.FileInputFormat: Total input paths to process : 1
14/08/15 14:01:43 INFO mapreduce.JobSubmitter: number of splits:1
14/08/15 14:01:43 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/08/15 14:01:43 INFO Configuration.deprecation: mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress
14/08/15 14:01:43 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/08/15 14:01:43 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 14:01:43 INFO Configuration.deprecation: mapred.job.reduce.memory.mb is deprecated. Instead, use mapreduce.reduce.memory.mb
14/08/15 14:01:43 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/08/15 14:01:43 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/08/15 14:01:43 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/08/15 14:01:43 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
14/08/15 14:01:43 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/08/15 14:01:43 INFO Configuration.deprecation: mapred.output.compression.type is deprecated. Instead, use mapreduce.output.fileoutputformat.compress.type
14/08/15 14:01:43 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/08/15 14:01:43 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/08/15 14:01:43 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/08/15 14:01:43 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/08/15 14:01:43 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/08/15 14:01:43 INFO Configuration.deprecation: mapred.job.map.memory.mb is deprecated. Instead, use mapreduce.map.memory.mb
14/08/15 14:01:43 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/08/15 14:01:43 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1408131000469_0119
14/08/15 14:01:43 INFO mapreduce.JobSubmitter: Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 871 for gpadmin)
14/08/15 14:01:43 INFO impl.YarnClientImpl: Submitted application application_1408131000469_0119 to ResourceManager at /0.0.0.0:8032
14/08/15 14:01:43 INFO mapreduce.Job: The url to track the job: http://0.0.0.0:9999/proxy/application_1408131000469_0119/
14/08/15 14:01:43 INFO mapreduce.Job: Running job: job_1408131000469_0119
14/08/15 14:01:53 INFO mapreduce.Job: Job job_1408131000469_0119 running in uber mode : false
14/08/15 14:01:53 INFO mapreduce.Job:  map 0% reduce 0%
14/08/15 14:01:59 INFO mapreduce.Job:  map 100% reduce 0%
14/08/15 14:02:05 INFO mapreduce.Job:  map 100% reduce 100%
14/08/15 14:02:05 INFO mapreduce.Job: Job job_1408131000469_0119 completed successfully
14/08/15 14:02:05 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=864014
		FILE: Number of bytes written=1897513
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=602634
		HDFS: Number of bytes written=70814
		HDFS: Number of read operations=6
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=11049
		Total time spent by all reduces in occupied slots (ms)=11421
	Map-Reduce Framework
		Map input records=5000
		Map output records=5000
		Map output bytes=849008
		Map output materialized bytes=864014
		Input split bytes=122
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=864014
		Reduce input records=5000
		Reduce output records=5000
		Spilled Records=10000
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=40
		CPU time spent (ms)=3000
		Physical memory (bytes) snapshot=1011904512
		Virtual memory (bytes) snapshot=6100451328
		Total committed heap usage (bytes)=1373372416
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=602512
	File Output Format Counters 
		Bytes Written=70814
create readable external table timestamp_readhdfs_mapreduce_blockcomp(like timestamp_readhdfs_mapreduce) location ('gphdfs://sdw1.dh.greenplum.com:8020/mapreduce/blockcomp/timestamp')format 'custom' (formatter='gphdfs_import');
CREATE EXTERNAL TABLE
\!export HADOOP_HOME=/usr/lib/gphd/hadoop/; source /data/gpadmin/gpdb/greenplum/lib/hadoop/hadoop_env.sh; java -cp .:$CLASSPATH:/data/gpadmin/gpdb/greenplum/lib/hadoop/gphd-2.0.2-gnet-1.2.0.0.jar:/data/gpadmin/workspace/tincrepo/main/mpp/gpdb/tests/package/gphdfs/maptest.jar -Dhdfshost=sdw1.dh.greenplum.com -Ddatanodeport=8020 -Djobtrackerhost=sdw1.dh.greenplum.com -Djobtrackerport=8020  -DcompressionType=block javaclasses/TestHadoopIntegration mapred Mapred_mapper_TextIn /plaintext/timestamp.txt /mapred/blockcomp/timestamp
14/08/15 14:02:06 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 14:02:06 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
14/08/15 14:02:06 INFO Configuration.deprecation: mapred.job.map.memory.mb is deprecated. Instead, use mapreduce.map.memory.mb
14/08/15 14:02:06 INFO Configuration.deprecation: mapred.job.reduce.memory.mb is deprecated. Instead, use mapreduce.reduce.memory.mb
14/08/15 14:02:06 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/08/15 14:02:07 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
14/08/15 14:02:07 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
14/08/15 14:02:08 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 872 for gpadmin on 192.168.2.100:8020
14/08/15 14:02:08 INFO security.TokenCache: Got dt for hdfs://sdw1.dh.greenplum.com:8020; Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 872 for gpadmin)
14/08/15 14:02:08 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/08/15 14:02:08 INFO mapred.FileInputFormat: Total input paths to process : 1
14/08/15 14:02:08 INFO mapreduce.JobSubmitter: number of splits:2
14/08/15 14:02:08 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/08/15 14:02:08 INFO Configuration.deprecation: mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress
14/08/15 14:02:08 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/08/15 14:02:08 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 14:02:08 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/08/15 14:02:08 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/08/15 14:02:08 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
14/08/15 14:02:08 INFO Configuration.deprecation: mapred.output.compression.type is deprecated. Instead, use mapreduce.output.fileoutputformat.compress.type
14/08/15 14:02:08 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/08/15 14:02:08 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/08/15 14:02:08 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/08/15 14:02:08 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/08/15 14:02:08 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/08/15 14:02:08 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1408131000469_0120
14/08/15 14:02:08 INFO mapreduce.JobSubmitter: Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 872 for gpadmin)
14/08/15 14:02:08 INFO impl.YarnClientImpl: Submitted application application_1408131000469_0120 to ResourceManager at /0.0.0.0:8032
14/08/15 14:02:09 INFO mapreduce.Job: The url to track the job: http://0.0.0.0:9999/proxy/application_1408131000469_0120/
14/08/15 14:02:09 INFO mapreduce.Job: Running job: job_1408131000469_0120
14/08/15 14:02:19 INFO mapreduce.Job: Job job_1408131000469_0120 running in uber mode : false
14/08/15 14:02:19 INFO mapreduce.Job:  map 0% reduce 0%
14/08/15 14:02:25 INFO mapreduce.Job:  map 100% reduce 0%
14/08/15 14:02:31 INFO mapreduce.Job:  map 100% reduce 100%
14/08/15 14:02:31 INFO mapreduce.Job: Job job_1408131000469_0120 completed successfully
14/08/15 14:02:31 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=864014
		FILE: Number of bytes written=1981747
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=604578
		HDFS: Number of bytes written=70814
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=20610
		Total time spent by all reduces in occupied slots (ms)=11172
	Map-Reduce Framework
		Map input records=5000
		Map output records=5000
		Map output bytes=849008
		Map output materialized bytes=864020
		Input split bytes=218
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=864020
		Reduce input records=5000
		Reduce output records=5000
		Spilled Records=10000
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=57
		CPU time spent (ms)=3700
		Physical memory (bytes) snapshot=1793794048
		Virtual memory (bytes) snapshot=8291004416
		Total committed heap usage (bytes)=2242641920
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=604360
	File Output Format Counters 
		Bytes Written=70814
create readable external table timestamp_readhdfs_mapred_blockcomp(like timestamp_readhdfs_mapreduce) location ('gphdfs://sdw1.dh.greenplum.com:8020/mapred/blockcomp/timestamp')format 'custom' (formatter='gphdfs_import');
CREATE EXTERNAL TABLE
(select * from timestamp_readhdfs_mapreduce_blockcomp except select * from timestamp_readhdfs_mapred_blockcomp) union (select * from timestamp_readhdfs_mapred_blockcomp except select * from timestamp_readhdfs_mapreduce_blockcomp);
 datatype_timestamp | xcount_timestamp | col1_timestamp | col2_timestamp | col3_timestamp | nullcol_timestamp 
--------------------+------------------+----------------+----------------+----------------+-------------------
(0 rows)

\!export HADOOP_HOME=/usr/lib/gphd/hadoop/; source /data/gpadmin/gpdb/greenplum/lib/hadoop/hadoop_env.sh; java -cp .:$CLASSPATH:/data/gpadmin/gpdb/greenplum/lib/hadoop/gphd-2.0.2-gnet-1.2.0.0.jar:/data/gpadmin/workspace/tincrepo/main/mpp/gpdb/tests/package/gphdfs/maptest.jar -Dhdfshost=sdw1.dh.greenplum.com -Ddatanodeport=8020 -Djobtrackerhost=sdw1.dh.greenplum.com -Djobtrackerport=8020  -DcompressionType=record javaclasses/TestHadoopIntegration mapreduce Mapreduce_mapper_TextIn /plaintext/timestamp.txt /mapreduce/recordcomp/timestamp
14/08/15 14:02:41 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 14:02:42 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/08/15 14:02:43 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
14/08/15 14:02:43 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 881 for gpadmin on 192.168.2.100:8020
14/08/15 14:02:43 INFO security.TokenCache: Got dt for hdfs://sdw1.dh.greenplum.com:8020; Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 881 for gpadmin)
14/08/15 14:02:43 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/08/15 14:02:44 INFO input.FileInputFormat: Total input paths to process : 1
14/08/15 14:02:44 INFO mapreduce.JobSubmitter: number of splits:1
14/08/15 14:02:44 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/08/15 14:02:44 INFO Configuration.deprecation: mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress
14/08/15 14:02:44 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/08/15 14:02:44 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 14:02:44 INFO Configuration.deprecation: mapred.job.reduce.memory.mb is deprecated. Instead, use mapreduce.reduce.memory.mb
14/08/15 14:02:44 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/08/15 14:02:44 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/08/15 14:02:44 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/08/15 14:02:44 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
14/08/15 14:02:44 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/08/15 14:02:44 INFO Configuration.deprecation: mapred.output.compression.type is deprecated. Instead, use mapreduce.output.fileoutputformat.compress.type
14/08/15 14:02:44 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/08/15 14:02:44 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/08/15 14:02:44 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/08/15 14:02:44 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/08/15 14:02:44 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/08/15 14:02:44 INFO Configuration.deprecation: mapred.job.map.memory.mb is deprecated. Instead, use mapreduce.map.memory.mb
14/08/15 14:02:44 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/08/15 14:02:44 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1408131000469_0121
14/08/15 14:02:44 INFO mapreduce.JobSubmitter: Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 881 for gpadmin)
14/08/15 14:02:44 INFO impl.YarnClientImpl: Submitted application application_1408131000469_0121 to ResourceManager at /0.0.0.0:8032
14/08/15 14:02:44 INFO mapreduce.Job: The url to track the job: http://0.0.0.0:9999/proxy/application_1408131000469_0121/
14/08/15 14:02:44 INFO mapreduce.Job: Running job: job_1408131000469_0121
14/08/15 14:02:53 INFO mapreduce.Job: Job job_1408131000469_0121 running in uber mode : false
14/08/15 14:02:53 INFO mapreduce.Job:  map 0% reduce 0%
14/08/15 14:02:59 INFO mapreduce.Job:  map 100% reduce 0%
14/08/15 14:03:05 INFO mapreduce.Job:  map 100% reduce 100%
14/08/15 14:03:05 INFO mapreduce.Job: Job job_1408131000469_0121 completed successfully
14/08/15 14:03:05 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=864014
		FILE: Number of bytes written=1897517
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=602634
		HDFS: Number of bytes written=535392
		HDFS: Number of read operations=6
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=10965
		Total time spent by all reduces in occupied slots (ms)=11538
	Map-Reduce Framework
		Map input records=5000
		Map output records=5000
		Map output bytes=849008
		Map output materialized bytes=864014
		Input split bytes=122
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=864014
		Reduce input records=5000
		Reduce output records=5000
		Spilled Records=10000
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=41
		CPU time spent (ms)=3340
		Physical memory (bytes) snapshot=1019469824
		Virtual memory (bytes) snapshot=6100451328
		Total committed heap usage (bytes)=1373372416
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=602512
	File Output Format Counters 
		Bytes Written=535392
create readable external table timestamp_readhdfs_mapreduce_recordcomp(like timestamp_readhdfs_mapreduce) location ('gphdfs://sdw1.dh.greenplum.com:8020/mapreduce/recordcomp/timestamp')format 'custom' (formatter='gphdfs_import');
CREATE EXTERNAL TABLE
\!export HADOOP_HOME=/usr/lib/gphd/hadoop/; source /data/gpadmin/gpdb/greenplum/lib/hadoop/hadoop_env.sh; java -cp .:$CLASSPATH:/data/gpadmin/gpdb/greenplum/lib/hadoop/gphd-2.0.2-gnet-1.2.0.0.jar:/data/gpadmin/workspace/tincrepo/main/mpp/gpdb/tests/package/gphdfs/maptest.jar -Dhdfshost=sdw1.dh.greenplum.com -Ddatanodeport=8020 -Djobtrackerhost=sdw1.dh.greenplum.com -Djobtrackerport=8020  -DcompressionType=record javaclasses/TestHadoopIntegration mapred Mapred_mapper_TextIn /plaintext/timestamp.txt /mapred/recordcomp/timestamp
14/08/15 14:03:06 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 14:03:06 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
14/08/15 14:03:06 INFO Configuration.deprecation: mapred.job.map.memory.mb is deprecated. Instead, use mapreduce.map.memory.mb
14/08/15 14:03:06 INFO Configuration.deprecation: mapred.job.reduce.memory.mb is deprecated. Instead, use mapreduce.reduce.memory.mb
14/08/15 14:03:06 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/08/15 14:03:07 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
14/08/15 14:03:08 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
14/08/15 14:03:08 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 882 for gpadmin on 192.168.2.100:8020
14/08/15 14:03:08 INFO security.TokenCache: Got dt for hdfs://sdw1.dh.greenplum.com:8020; Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 882 for gpadmin)
14/08/15 14:03:08 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/08/15 14:03:08 INFO mapred.FileInputFormat: Total input paths to process : 1
14/08/15 14:03:08 INFO mapreduce.JobSubmitter: number of splits:2
14/08/15 14:03:08 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/08/15 14:03:08 INFO Configuration.deprecation: mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress
14/08/15 14:03:08 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/08/15 14:03:08 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 14:03:08 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/08/15 14:03:08 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/08/15 14:03:08 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
14/08/15 14:03:08 INFO Configuration.deprecation: mapred.output.compression.type is deprecated. Instead, use mapreduce.output.fileoutputformat.compress.type
14/08/15 14:03:08 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/08/15 14:03:08 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/08/15 14:03:08 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/08/15 14:03:08 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/08/15 14:03:08 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/08/15 14:03:08 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1408131000469_0122
14/08/15 14:03:08 INFO mapreduce.JobSubmitter: Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 882 for gpadmin)
14/08/15 14:03:09 INFO impl.YarnClientImpl: Submitted application application_1408131000469_0122 to ResourceManager at /0.0.0.0:8032
14/08/15 14:03:09 INFO mapreduce.Job: The url to track the job: http://0.0.0.0:9999/proxy/application_1408131000469_0122/
14/08/15 14:03:09 INFO mapreduce.Job: Running job: job_1408131000469_0122
14/08/15 14:03:19 INFO mapreduce.Job: Job job_1408131000469_0122 running in uber mode : false
14/08/15 14:03:19 INFO mapreduce.Job:  map 0% reduce 0%
14/08/15 14:03:25 INFO mapreduce.Job:  map 100% reduce 0%
14/08/15 14:03:31 INFO mapreduce.Job:  map 100% reduce 100%
14/08/15 14:03:31 INFO mapreduce.Job: Job job_1408131000469_0122 completed successfully
14/08/15 14:03:31 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=864014
		FILE: Number of bytes written=1981753
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=604578
		HDFS: Number of bytes written=535392
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=22278
		Total time spent by all reduces in occupied slots (ms)=12318
	Map-Reduce Framework
		Map input records=5000
		Map output records=5000
		Map output bytes=849008
		Map output materialized bytes=864020
		Input split bytes=218
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=864020
		Reduce input records=5000
		Reduce output records=5000
		Spilled Records=10000
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=57
		CPU time spent (ms)=4560
		Physical memory (bytes) snapshot=1806073856
		Virtual memory (bytes) snapshot=8290717696
		Total committed heap usage (bytes)=2242641920
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=604360
	File Output Format Counters 
		Bytes Written=535392
create readable external table timestamp_readhdfs_mapred_recordcomp(like timestamp_readhdfs_mapreduce) location ('gphdfs://sdw1.dh.greenplum.com:8020/mapred/recordcomp/timestamp')format 'custom' (formatter='gphdfs_import');
CREATE EXTERNAL TABLE
(select * from timestamp_readhdfs_mapreduce_recordcomp except select * from timestamp_readhdfs_mapred_recordcomp) union (select * from timestamp_readhdfs_mapred_recordcomp except select * from timestamp_readhdfs_mapreduce_recordcomp);
 datatype_timestamp | xcount_timestamp | col1_timestamp | col2_timestamp | col3_timestamp | nullcol_timestamp 
--------------------+------------------+----------------+----------------+----------------+-------------------
(0 rows)

(select * from timestamp_readhdfs_mapreduce_recordcomp except select * from timestamp_readhdfs_mapred_blockcomp) union (select * from timestamp_readhdfs_mapred_blockcomp except select * from timestamp_readhdfs_mapreduce_recordcomp);
 datatype_timestamp | xcount_timestamp | col1_timestamp | col2_timestamp | col3_timestamp | nullcol_timestamp 
--------------------+------------------+----------------+----------------+----------------+-------------------
(0 rows)

(select * from timestamp_readhdfs_mapreduce except select * from timestamp_readhdfs_mapred_recordcomp) union (select * from timestamp_readhdfs_mapred_recordcomp except select * from timestamp_readhdfs_mapreduce);
 datatype_timestamp | xcount_timestamp | col1_timestamp | col2_timestamp | col3_timestamp | nullcol_timestamp 
--------------------+------------------+----------------+----------------+----------------+-------------------
(0 rows)

(select * from timestamp_readhdfs_mapreduce except select * from timestamp_heap) union (select * from timestamp_heap except select * from timestamp_readhdfs_mapreduce);
 datatype_timestamp | xcount_timestamp | col1_timestamp | col2_timestamp | col3_timestamp | nullcol_timestamp 
--------------------+------------------+----------------+----------------+----------------+-------------------
(0 rows)


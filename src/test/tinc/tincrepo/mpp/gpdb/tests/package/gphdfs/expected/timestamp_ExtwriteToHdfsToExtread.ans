-- start_ignore
-- end_ignore
\echo --start_ignore
--start_ignore
drop external table timestamp_heap;
DROP EXTERNAL TABLE
drop external table timestamp_writehdfs;
DROP EXTERNAL TABLE
drop external table timestamp_verification_mapreduce;
DROP EXTERNAL TABLE
drop external table timestamp_verification_mapred;
DROP EXTERNAL TABLE
drop external table timestamp_verification_blockcomp_mapreduce;
DROP EXTERNAL TABLE
drop external table timestamp_verification_blockcomp_mapred;
DROP EXTERNAL TABLE
drop external table timestamp_verification_recordcomp_mapreduce;
DROP EXTERNAL TABLE
drop external table timestamp_verification_recordcomp_mapred;
DROP EXTERNAL TABLE
\echo --end_ignore
--end_ignore
create readable external table timestamp_heap(datatype_timestamp varchar,xcount_timestamp bigint, col1_timestamp timestamp,col2_timestamp timestamp, col3_timestamp timestamp, nullcol_timestamp timestamp) location ('gpfdist://sdw1.dh.greenplum.com:8080/timestamp.txt')format 'TEXT';
CREATE EXTERNAL TABLE
create writable external table timestamp_writehdfs(like timestamp_heap) location ('gphdfs://sdw1.dh.greenplum.com:8020/extwrite/timestamp')format 'custom' (formatter='gphdfs_export');
psql:/path/sql_file:1: NOTICE:  Table doesn't have 'distributed by' clause, defaulting to distribution columns from LIKE table
CREATE EXTERNAL TABLE
insert into timestamp_writehdfs select * from timestamp_heap;
INSERT 0 5000
\!export HADOOP_HOME=/usr/lib/gphd/hadoop/; source /data/gpadmin/gpdb/greenplum/lib/hadoop/hadoop_env.sh; java -cp .:$CLASSPATH:/data/gpadmin/gpdb/greenplum/lib/hadoop/gphd-2.0.2-gnet-1.2.0.0.jar:/data/gpadmin/workspace/tincrepo/main/mpp/gpdb/tests/package/gphdfs/maptest.jar -Dhdfshost=sdw1.dh.greenplum.com -Ddatanodeport=8020 -Djobtrackerhost=sdw1.dh.greenplum.com -Djobtrackerport=8020  -DcompressionType=none javaclasses/TestHadoopIntegration mapreduce Mapreduce_mapper_GPDB_INOUT /extwrite/timestamp /mapreduce/timestamp_gpdb/ 
14/08/15 13:56:43 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 13:56:44 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/08/15 13:56:45 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
14/08/15 13:56:45 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 803 for gpadmin on 192.168.2.100:8020
14/08/15 13:56:45 INFO security.TokenCache: Got dt for hdfs://sdw1.dh.greenplum.com:8020; Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 803 for gpadmin)
14/08/15 13:56:45 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/08/15 13:56:45 INFO input.FileInputFormat: Total input paths to process : 2
14/08/15 13:56:45 INFO mapreduce.JobSubmitter: number of splits:2
14/08/15 13:56:45 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/08/15 13:56:45 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/08/15 13:56:45 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 13:56:45 INFO Configuration.deprecation: mapred.job.reduce.memory.mb is deprecated. Instead, use mapreduce.reduce.memory.mb
14/08/15 13:56:45 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/08/15 13:56:45 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/08/15 13:56:45 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/08/15 13:56:45 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
14/08/15 13:56:45 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/08/15 13:56:45 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/08/15 13:56:45 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/08/15 13:56:45 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/08/15 13:56:45 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/08/15 13:56:45 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/08/15 13:56:45 INFO Configuration.deprecation: mapred.job.map.memory.mb is deprecated. Instead, use mapreduce.map.memory.mb
14/08/15 13:56:45 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/08/15 13:56:46 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1408131000469_0111
14/08/15 13:56:46 INFO mapreduce.JobSubmitter: Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 803 for gpadmin)
14/08/15 13:56:46 INFO impl.YarnClientImpl: Submitted application application_1408131000469_0111 to ResourceManager at /0.0.0.0:8032
14/08/15 13:56:46 INFO mapreduce.Job: The url to track the job: http://0.0.0.0:9999/proxy/application_1408131000469_0111/
14/08/15 13:56:46 INFO mapreduce.Job: Running job: job_1408131000469_0111
14/08/15 13:56:54 INFO mapreduce.Job: Job job_1408131000469_0111 running in uber mode : false
14/08/15 13:56:54 INFO mapreduce.Job:  map 0% reduce 0%
14/08/15 13:57:00 INFO mapreduce.Job:  map 100% reduce 0%
14/08/15 13:57:07 INFO mapreduce.Job:  map 100% reduce 100%
14/08/15 13:57:07 INFO mapreduce.Job: Job job_1408131000469_0111 completed successfully
14/08/15 13:57:07 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=775006
		FILE: Number of bytes written=1804265
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=808174
		HDFS: Number of bytes written=807786
		HDFS: Number of read operations=11
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=23940
		Total time spent by all reduces in occupied slots (ms)=11094
	Map-Reduce Framework
		Map input records=5000
		Map output records=5000
		Map output bytes=760000
		Map output materialized bytes=775012
		Input split bytes=282
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=775012
		Reduce input records=5000
		Reduce output records=5000
		Spilled Records=10000
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=46
		CPU time spent (ms)=5560
		Physical memory (bytes) snapshot=1790742528
		Virtual memory (bytes) snapshot=8288530432
		Total committed heap usage (bytes)=2242641920
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=807892
	File Output Format Counters 
		Bytes Written=807786
\!export HADOOP_HOME=/usr/lib/gphd/hadoop/; source /data/gpadmin/gpdb/greenplum/lib/hadoop/hadoop_env.sh; java -cp .:$CLASSPATH:/data/gpadmin/gpdb/greenplum/lib/hadoop/gphd-2.0.2-gnet-1.2.0.0.jar:/data/gpadmin/workspace/tincrepo/main/mpp/gpdb/tests/package/gphdfs/maptest.jar -Dhdfshost=sdw1.dh.greenplum.com -Ddatanodeport=8020 -Djobtrackerhost=sdw1.dh.greenplum.com -Djobtrackerport=8020  -DcompressionType=none javaclasses/TestHadoopIntegration mapred Mapred_mapper_GPDB_INOUT /extwrite/timestamp /mapred/timestamp_gpdb/
14/08/15 13:57:08 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 13:57:08 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
14/08/15 13:57:08 INFO Configuration.deprecation: mapred.job.map.memory.mb is deprecated. Instead, use mapreduce.map.memory.mb
14/08/15 13:57:08 INFO Configuration.deprecation: mapred.job.reduce.memory.mb is deprecated. Instead, use mapreduce.reduce.memory.mb
14/08/15 13:57:09 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/08/15 13:57:10 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
14/08/15 13:57:10 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
14/08/15 13:57:10 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 804 for gpadmin on 192.168.2.100:8020
14/08/15 13:57:10 INFO security.TokenCache: Got dt for hdfs://sdw1.dh.greenplum.com:8020; Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 804 for gpadmin)
14/08/15 13:57:10 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/08/15 13:57:11 INFO mapred.FileInputFormat: Total input paths to process : 2
14/08/15 13:57:11 INFO mapreduce.JobSubmitter: number of splits:2
14/08/15 13:57:11 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/08/15 13:57:11 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/08/15 13:57:11 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 13:57:11 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/08/15 13:57:11 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/08/15 13:57:11 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
14/08/15 13:57:11 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/08/15 13:57:11 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/08/15 13:57:11 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/08/15 13:57:11 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/08/15 13:57:11 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/08/15 13:57:11 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1408131000469_0112
14/08/15 13:57:11 INFO mapreduce.JobSubmitter: Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 804 for gpadmin)
14/08/15 13:57:11 INFO impl.YarnClientImpl: Submitted application application_1408131000469_0112 to ResourceManager at /0.0.0.0:8032
14/08/15 13:57:11 INFO mapreduce.Job: The url to track the job: http://0.0.0.0:9999/proxy/application_1408131000469_0112/
14/08/15 13:57:11 INFO mapreduce.Job: Running job: job_1408131000469_0112
14/08/15 13:57:22 INFO mapreduce.Job: Job job_1408131000469_0112 running in uber mode : false
14/08/15 13:57:22 INFO mapreduce.Job:  map 0% reduce 0%
14/08/15 13:57:28 INFO mapreduce.Job:  map 100% reduce 0%
14/08/15 13:57:35 INFO mapreduce.Job:  map 100% reduce 100%
14/08/15 13:57:35 INFO mapreduce.Job: Job job_1408131000469_0112 completed successfully
14/08/15 13:57:35 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=775006
		FILE: Number of bytes written=1803773
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=808148
		HDFS: Number of bytes written=807786
		HDFS: Number of read operations=11
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=23496
		Total time spent by all reduces in occupied slots (ms)=13743
	Map-Reduce Framework
		Map input records=5000
		Map output records=5000
		Map output bytes=760000
		Map output materialized bytes=775012
		Input split bytes=256
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=775012
		Reduce input records=5000
		Reduce output records=5000
		Spilled Records=10000
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=57
		CPU time spent (ms)=7220
		Physical memory (bytes) snapshot=1798127616
		Virtual memory (bytes) snapshot=8288530432
		Total committed heap usage (bytes)=2242641920
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=807892
	File Output Format Counters 
		Bytes Written=807786
\!export HADOOP_HOME=/usr/lib/gphd/hadoop/; source /data/gpadmin/gpdb/greenplum/lib/hadoop/hadoop_env.sh; java -cp .:$CLASSPATH:/data/gpadmin/gpdb/greenplum/lib/hadoop/gphd-2.0.2-gnet-1.2.0.0.jar:/data/gpadmin/workspace/tincrepo/main/mpp/gpdb/tests/package/gphdfs/maptest.jar -Dhdfshost=sdw1.dh.greenplum.com -Ddatanodeport=8020 -Djobtrackerhost=sdw1.dh.greenplum.com -Djobtrackerport=8020  -DcompressionType=block javaclasses/TestHadoopIntegration mapreduce Mapreduce_mapper_GPDB_INOUT /extwrite/timestamp /mapreduce/blockcomp/timestamp_gpdb/
14/08/15 13:57:36 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 13:57:36 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/08/15 13:57:38 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
14/08/15 13:57:38 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 805 for gpadmin on 192.168.2.100:8020
14/08/15 13:57:38 INFO security.TokenCache: Got dt for hdfs://sdw1.dh.greenplum.com:8020; Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 805 for gpadmin)
14/08/15 13:57:38 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/08/15 13:57:39 INFO input.FileInputFormat: Total input paths to process : 2
14/08/15 13:57:39 INFO mapreduce.JobSubmitter: number of splits:2
14/08/15 13:57:39 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/08/15 13:57:39 INFO Configuration.deprecation: mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress
14/08/15 13:57:39 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/08/15 13:57:39 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 13:57:39 INFO Configuration.deprecation: mapred.job.reduce.memory.mb is deprecated. Instead, use mapreduce.reduce.memory.mb
14/08/15 13:57:39 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/08/15 13:57:39 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/08/15 13:57:39 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/08/15 13:57:39 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
14/08/15 13:57:39 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/08/15 13:57:39 INFO Configuration.deprecation: mapred.output.compression.type is deprecated. Instead, use mapreduce.output.fileoutputformat.compress.type
14/08/15 13:57:39 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/08/15 13:57:39 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/08/15 13:57:39 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/08/15 13:57:39 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/08/15 13:57:39 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/08/15 13:57:39 INFO Configuration.deprecation: mapred.job.map.memory.mb is deprecated. Instead, use mapreduce.map.memory.mb
14/08/15 13:57:39 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/08/15 13:57:39 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1408131000469_0113
14/08/15 13:57:39 INFO mapreduce.JobSubmitter: Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 805 for gpadmin)
14/08/15 13:57:39 INFO impl.YarnClientImpl: Submitted application application_1408131000469_0113 to ResourceManager at /0.0.0.0:8032
14/08/15 13:57:39 INFO mapreduce.Job: The url to track the job: http://0.0.0.0:9999/proxy/application_1408131000469_0113/
14/08/15 13:57:39 INFO mapreduce.Job: Running job: job_1408131000469_0113
14/08/15 13:57:50 INFO mapreduce.Job: Job job_1408131000469_0113 running in uber mode : false
14/08/15 13:57:50 INFO mapreduce.Job:  map 0% reduce 0%
14/08/15 13:57:56 INFO mapreduce.Job:  map 100% reduce 0%
14/08/15 13:58:02 INFO mapreduce.Job:  map 100% reduce 100%
14/08/15 13:58:02 INFO mapreduce.Job: Job job_1408131000469_0113 completed successfully
14/08/15 13:58:02 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=775006
		FILE: Number of bytes written=1804271
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=808174
		HDFS: Number of bytes written=57692
		HDFS: Number of read operations=11
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=21681
		Total time spent by all reduces in occupied slots (ms)=11598
	Map-Reduce Framework
		Map input records=5000
		Map output records=5000
		Map output bytes=760000
		Map output materialized bytes=775012
		Input split bytes=282
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=775012
		Reduce input records=5000
		Reduce output records=5000
		Spilled Records=10000
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=64
		CPU time spent (ms)=4870
		Physical memory (bytes) snapshot=1806417920
		Virtual memory (bytes) snapshot=8290717696
		Total committed heap usage (bytes)=2242641920
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=807892
	File Output Format Counters 
		Bytes Written=57692
\!export HADOOP_HOME=/usr/lib/gphd/hadoop/; source /data/gpadmin/gpdb/greenplum/lib/hadoop/hadoop_env.sh; java -cp .:$CLASSPATH:/data/gpadmin/gpdb/greenplum/lib/hadoop/gphd-2.0.2-gnet-1.2.0.0.jar:/data/gpadmin/workspace/tincrepo/main/mpp/gpdb/tests/package/gphdfs/maptest.jar -Dhdfshost=sdw1.dh.greenplum.com -Ddatanodeport=8020 -Djobtrackerhost=sdw1.dh.greenplum.com -Djobtrackerport=8020  -DcompressionType=block javaclasses/TestHadoopIntegration mapred Mapred_mapper_GPDB_INOUT /extwrite/timestamp /mapred/blockcomp/timestamp_gpdb/
14/08/15 13:58:03 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 13:58:03 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
14/08/15 13:58:03 INFO Configuration.deprecation: mapred.job.map.memory.mb is deprecated. Instead, use mapreduce.map.memory.mb
14/08/15 13:58:03 INFO Configuration.deprecation: mapred.job.reduce.memory.mb is deprecated. Instead, use mapreduce.reduce.memory.mb
14/08/15 13:58:03 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/08/15 13:58:04 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
14/08/15 13:58:04 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
14/08/15 13:58:05 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 806 for gpadmin on 192.168.2.100:8020
14/08/15 13:58:05 INFO security.TokenCache: Got dt for hdfs://sdw1.dh.greenplum.com:8020; Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 806 for gpadmin)
14/08/15 13:58:05 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/08/15 13:58:05 INFO mapred.FileInputFormat: Total input paths to process : 2
14/08/15 13:58:05 INFO mapreduce.JobSubmitter: number of splits:2
14/08/15 13:58:05 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/08/15 13:58:05 INFO Configuration.deprecation: mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress
14/08/15 13:58:05 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/08/15 13:58:05 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 13:58:05 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/08/15 13:58:05 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/08/15 13:58:05 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
14/08/15 13:58:05 INFO Configuration.deprecation: mapred.output.compression.type is deprecated. Instead, use mapreduce.output.fileoutputformat.compress.type
14/08/15 13:58:05 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/08/15 13:58:05 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/08/15 13:58:05 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/08/15 13:58:05 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/08/15 13:58:05 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/08/15 13:58:05 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1408131000469_0114
14/08/15 13:58:05 INFO mapreduce.JobSubmitter: Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 806 for gpadmin)
14/08/15 13:58:06 INFO impl.YarnClientImpl: Submitted application application_1408131000469_0114 to ResourceManager at /0.0.0.0:8032
14/08/15 13:58:06 INFO mapreduce.Job: The url to track the job: http://0.0.0.0:9999/proxy/application_1408131000469_0114/
14/08/15 13:58:06 INFO mapreduce.Job: Running job: job_1408131000469_0114
14/08/15 13:58:16 INFO mapreduce.Job: Job job_1408131000469_0114 running in uber mode : false
14/08/15 13:58:16 INFO mapreduce.Job:  map 0% reduce 0%
14/08/15 13:58:22 INFO mapreduce.Job:  map 100% reduce 0%
14/08/15 13:58:29 INFO mapreduce.Job:  map 100% reduce 100%
14/08/15 13:58:29 INFO mapreduce.Job: Job job_1408131000469_0114 completed successfully
14/08/15 13:58:29 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=775006
		FILE: Number of bytes written=1803779
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=808148
		HDFS: Number of bytes written=57692
		HDFS: Number of read operations=11
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=24525
		Total time spent by all reduces in occupied slots (ms)=11697
	Map-Reduce Framework
		Map input records=5000
		Map output records=5000
		Map output bytes=760000
		Map output materialized bytes=775012
		Input split bytes=256
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=775012
		Reduce input records=5000
		Reduce output records=5000
		Spilled Records=10000
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=62
		CPU time spent (ms)=6030
		Physical memory (bytes) snapshot=1809838080
		Virtual memory (bytes) snapshot=8291004416
		Total committed heap usage (bytes)=2242641920
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=807892
	File Output Format Counters 
		Bytes Written=57692
\!export HADOOP_HOME=/usr/lib/gphd/hadoop/; source /data/gpadmin/gpdb/greenplum/lib/hadoop/hadoop_env.sh; java -cp .:$CLASSPATH:/data/gpadmin/gpdb/greenplum/lib/hadoop/gphd-2.0.2-gnet-1.2.0.0.jar:/data/gpadmin/workspace/tincrepo/main/mpp/gpdb/tests/package/gphdfs/maptest.jar -Dhdfshost=sdw1.dh.greenplum.com -Ddatanodeport=8020 -Djobtrackerhost=sdw1.dh.greenplum.com -Djobtrackerport=8020  -DcompressionType=record javaclasses/TestHadoopIntegration mapreduce Mapreduce_mapper_GPDB_INOUT /extwrite/timestamp /mapreduce/recordcomp/timestamp_gpdb/
14/08/15 13:58:30 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 13:58:31 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/08/15 13:58:32 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
14/08/15 13:58:32 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 807 for gpadmin on 192.168.2.100:8020
14/08/15 13:58:32 INFO security.TokenCache: Got dt for hdfs://sdw1.dh.greenplum.com:8020; Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 807 for gpadmin)
14/08/15 13:58:32 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/08/15 13:58:32 INFO input.FileInputFormat: Total input paths to process : 2
14/08/15 13:58:32 INFO mapreduce.JobSubmitter: number of splits:2
14/08/15 13:58:32 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/08/15 13:58:32 INFO Configuration.deprecation: mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress
14/08/15 13:58:32 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/08/15 13:58:32 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 13:58:32 INFO Configuration.deprecation: mapred.job.reduce.memory.mb is deprecated. Instead, use mapreduce.reduce.memory.mb
14/08/15 13:58:32 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/08/15 13:58:32 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/08/15 13:58:32 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/08/15 13:58:32 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
14/08/15 13:58:32 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/08/15 13:58:32 INFO Configuration.deprecation: mapred.output.compression.type is deprecated. Instead, use mapreduce.output.fileoutputformat.compress.type
14/08/15 13:58:32 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/08/15 13:58:32 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/08/15 13:58:32 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/08/15 13:58:32 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/08/15 13:58:32 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/08/15 13:58:32 INFO Configuration.deprecation: mapred.job.map.memory.mb is deprecated. Instead, use mapreduce.map.memory.mb
14/08/15 13:58:32 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/08/15 13:58:33 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1408131000469_0115
14/08/15 13:58:33 INFO mapreduce.JobSubmitter: Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 807 for gpadmin)
14/08/15 13:58:33 INFO impl.YarnClientImpl: Submitted application application_1408131000469_0115 to ResourceManager at /0.0.0.0:8032
14/08/15 13:58:33 INFO mapreduce.Job: The url to track the job: http://0.0.0.0:9999/proxy/application_1408131000469_0115/
14/08/15 13:58:33 INFO mapreduce.Job: Running job: job_1408131000469_0115
14/08/15 13:58:44 INFO mapreduce.Job: Job job_1408131000469_0115 running in uber mode : false
14/08/15 13:58:44 INFO mapreduce.Job:  map 0% reduce 0%
14/08/15 13:58:49 INFO mapreduce.Job:  map 100% reduce 0%
14/08/15 13:58:56 INFO mapreduce.Job:  map 100% reduce 100%
14/08/15 13:58:56 INFO mapreduce.Job: Job job_1408131000469_0115 completed successfully
14/08/15 13:58:56 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=775006
		FILE: Number of bytes written=1804277
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=808174
		HDFS: Number of bytes written=418584
		HDFS: Number of read operations=11
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=21714
		Total time spent by all reduces in occupied slots (ms)=11880
	Map-Reduce Framework
		Map input records=5000
		Map output records=5000
		Map output bytes=760000
		Map output materialized bytes=775012
		Input split bytes=282
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=775012
		Reduce input records=5000
		Reduce output records=5000
		Spilled Records=10000
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=161
		CPU time spent (ms)=5460
		Physical memory (bytes) snapshot=1808359424
		Virtual memory (bytes) snapshot=8290717696
		Total committed heap usage (bytes)=2242641920
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=807892
	File Output Format Counters 
		Bytes Written=418584
\!export HADOOP_HOME=/usr/lib/gphd/hadoop/; source /data/gpadmin/gpdb/greenplum/lib/hadoop/hadoop_env.sh; java -cp .:$CLASSPATH:/data/gpadmin/gpdb/greenplum/lib/hadoop/gphd-2.0.2-gnet-1.2.0.0.jar:/data/gpadmin/workspace/tincrepo/main/mpp/gpdb/tests/package/gphdfs/maptest.jar -Dhdfshost=sdw1.dh.greenplum.com -Ddatanodeport=8020 -Djobtrackerhost=sdw1.dh.greenplum.com -Djobtrackerport=8020  -DcompressionType=record javaclasses/TestHadoopIntegration mapred Mapred_mapper_GPDB_INOUT /extwrite/timestamp /mapred/recordcomp/timestamp_gpdb/
14/08/15 13:58:57 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 13:58:57 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
14/08/15 13:58:57 INFO Configuration.deprecation: mapred.job.map.memory.mb is deprecated. Instead, use mapreduce.map.memory.mb
14/08/15 13:58:57 INFO Configuration.deprecation: mapred.job.reduce.memory.mb is deprecated. Instead, use mapreduce.reduce.memory.mb
14/08/15 13:58:58 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/08/15 13:58:59 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
14/08/15 13:58:59 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
14/08/15 13:58:59 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 808 for gpadmin on 192.168.2.100:8020
14/08/15 13:58:59 INFO security.TokenCache: Got dt for hdfs://sdw1.dh.greenplum.com:8020; Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 808 for gpadmin)
14/08/15 13:58:59 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/08/15 13:59:00 INFO mapred.FileInputFormat: Total input paths to process : 2
14/08/15 13:59:00 INFO mapreduce.JobSubmitter: number of splits:2
14/08/15 13:59:00 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/08/15 13:59:00 INFO Configuration.deprecation: mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress
14/08/15 13:59:00 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/08/15 13:59:00 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 13:59:00 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/08/15 13:59:00 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/08/15 13:59:00 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
14/08/15 13:59:00 INFO Configuration.deprecation: mapred.output.compression.type is deprecated. Instead, use mapreduce.output.fileoutputformat.compress.type
14/08/15 13:59:00 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/08/15 13:59:00 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/08/15 13:59:00 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/08/15 13:59:00 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/08/15 13:59:00 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/08/15 13:59:00 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1408131000469_0116
14/08/15 13:59:00 INFO mapreduce.JobSubmitter: Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 808 for gpadmin)
14/08/15 13:59:00 INFO impl.YarnClientImpl: Submitted application application_1408131000469_0116 to ResourceManager at /0.0.0.0:8032
14/08/15 13:59:00 INFO mapreduce.Job: The url to track the job: http://0.0.0.0:9999/proxy/application_1408131000469_0116/
14/08/15 13:59:00 INFO mapreduce.Job: Running job: job_1408131000469_0116
14/08/15 13:59:10 INFO mapreduce.Job: Job job_1408131000469_0116 running in uber mode : false
14/08/15 13:59:10 INFO mapreduce.Job:  map 0% reduce 0%
14/08/15 13:59:16 INFO mapreduce.Job:  map 100% reduce 0%
14/08/15 13:59:22 INFO mapreduce.Job:  map 100% reduce 100%
14/08/15 13:59:23 INFO mapreduce.Job: Job job_1408131000469_0116 completed successfully
14/08/15 13:59:24 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=775006
		FILE: Number of bytes written=1803785
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=808148
		HDFS: Number of bytes written=418584
		HDFS: Number of read operations=11
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=21129
		Total time spent by all reduces in occupied slots (ms)=11991
	Map-Reduce Framework
		Map input records=5000
		Map output records=5000
		Map output bytes=760000
		Map output materialized bytes=775012
		Input split bytes=256
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=775012
		Reduce input records=5000
		Reduce output records=5000
		Spilled Records=10000
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=56
		CPU time spent (ms)=5340
		Physical memory (bytes) snapshot=1797701632
		Virtual memory (bytes) snapshot=8290717696
		Total committed heap usage (bytes)=2242641920
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=807892
	File Output Format Counters 
		Bytes Written=418584
create readable external table timestamp_verification_mapreduce(like timestamp_heap) location ('gphdfs://sdw1.dh.greenplum.com:8020/mapreduce/timestamp_gpdb/')format 'custom' (formatter='gphdfs_import');
CREATE EXTERNAL TABLE
create readable external table timestamp_verification_mapred(like timestamp_heap) location ('gphdfs://sdw1.dh.greenplum.com:8020/mapred/timestamp_gpdb/')format 'custom' (formatter='gphdfs_import');
CREATE EXTERNAL TABLE
create readable external table timestamp_verification_blockcomp_mapreduce(like timestamp_heap) location ('gphdfs://sdw1.dh.greenplum.com:8020/mapreduce/blockcomp/timestamp_gpdb/')format 'custom' (formatter='gphdfs_import');
CREATE EXTERNAL TABLE
create readable external table timestamp_verification_blockcomp_mapred(like timestamp_heap) location ('gphdfs://sdw1.dh.greenplum.com:8020/mapred/blockcomp/timestamp_gpdb/')format 'custom' (formatter='gphdfs_import');
CREATE EXTERNAL TABLE
create readable external table timestamp_verification_recordcomp_mapreduce(like timestamp_heap) location ('gphdfs://sdw1.dh.greenplum.com:8020/mapreduce/recordcomp/timestamp_gpdb/')format 'custom' (formatter='gphdfs_import');
CREATE EXTERNAL TABLE
create readable external table timestamp_verification_recordcomp_mapred(like timestamp_heap) location ('gphdfs://sdw1.dh.greenplum.com:8020/mapred/recordcomp/timestamp_gpdb/')format 'custom' (formatter='gphdfs_import');
CREATE EXTERNAL TABLE
(select * from timestamp_verification_mapreduce except select * from timestamp_verification_mapred) union (select * from timestamp_verification_mapred except select * from timestamp_verification_mapreduce);
 datatype_timestamp | xcount_timestamp | col1_timestamp | col2_timestamp | col3_timestamp | nullcol_timestamp 
--------------------+------------------+----------------+----------------+----------------+-------------------
(0 rows)

(select * from timestamp_verification_blockcomp_mapreduce except select * from timestamp_verification_blockcomp_mapred) union (select * from timestamp_verification_blockcomp_mapred except select * from timestamp_verification_blockcomp_mapreduce);
 datatype_timestamp | xcount_timestamp | col1_timestamp | col2_timestamp | col3_timestamp | nullcol_timestamp 
--------------------+------------------+----------------+----------------+----------------+-------------------
(0 rows)

(select * from timestamp_verification_recordcomp_mapreduce except select * from timestamp_verification_recordcomp_mapred) union (select * from timestamp_verification_recordcomp_mapred except select * from timestamp_verification_recordcomp_mapreduce);
 datatype_timestamp | xcount_timestamp | col1_timestamp | col2_timestamp | col3_timestamp | nullcol_timestamp 
--------------------+------------------+----------------+----------------+----------------+-------------------
(0 rows)

(select * from timestamp_verification_recordcomp_mapreduce except select * from timestamp_verification_blockcomp_mapreduce) union (select * from timestamp_verification_blockcomp_mapreduce except select * from timestamp_verification_recordcomp_mapreduce);
 datatype_timestamp | xcount_timestamp | col1_timestamp | col2_timestamp | col3_timestamp | nullcol_timestamp 
--------------------+------------------+----------------+----------------+----------------+-------------------
(0 rows)

(select * from timestamp_verification_recordcomp_mapreduce except select * from timestamp_verification_mapreduce) union (select * from timestamp_verification_mapreduce except select * from timestamp_verification_recordcomp_mapreduce);
 datatype_timestamp | xcount_timestamp | col1_timestamp | col2_timestamp | col3_timestamp | nullcol_timestamp 
--------------------+------------------+----------------+----------------+----------------+-------------------
(0 rows)

(select * from timestamp_verification_recordcomp_mapreduce except select * from timestamp_heap) union (select * from timestamp_heap except select * from timestamp_verification_recordcomp_mapreduce);
 datatype_timestamp | xcount_timestamp | col1_timestamp | col2_timestamp | col3_timestamp | nullcol_timestamp 
--------------------+------------------+----------------+----------------+----------------+-------------------
(0 rows)


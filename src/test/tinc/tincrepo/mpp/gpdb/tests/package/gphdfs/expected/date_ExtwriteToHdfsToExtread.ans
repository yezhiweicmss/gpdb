-- start_ignore
-- end_ignore
\echo --start_ignore
--start_ignore
drop external table date_heap;
DROP EXTERNAL TABLE
drop external table date_writehdfs;
DROP EXTERNAL TABLE
drop external table date_verification_mapreduce;
DROP EXTERNAL TABLE
drop external table date_verification_mapred;
DROP EXTERNAL TABLE
drop external table date_verification_blockcomp_mapreduce;
DROP EXTERNAL TABLE
drop external table date_verification_blockcomp_mapred;
DROP EXTERNAL TABLE
drop external table date_verification_recordcomp_mapreduce;
DROP EXTERNAL TABLE
drop external table date_verification_recordcomp_mapred;
DROP EXTERNAL TABLE
\echo --end_ignore
--end_ignore
create readable external table date_heap(
datatype_date varchar,x_date bigint, col1_date date,col2_date date, col3_date date, col4_date date, col5_date date, col6_date date, col7_date date, nullcol_date date
) location ('gpfdist://sdw1.dh.greenplum.com:8080/date.txt')format 'TEXT';
CREATE EXTERNAL TABLE
create writable external table date_writehdfs(like date_heap) location ('gphdfs://sdw1.dh.greenplum.com:8020/extwrite/date')format 'custom' (formatter='gphdfs_export');
psql:/path/sql_file:1: NOTICE:  Table doesn't have 'distributed by' clause, defaulting to distribution columns from LIKE table
CREATE EXTERNAL TABLE
insert into date_writehdfs select * from date_heap;
INSERT 0 5000
\!export HADOOP_HOME=/usr/lib/gphd/hadoop/; source /data/gpadmin/gpdb/greenplum/lib/hadoop/hadoop_env.sh; java -cp .:$CLASSPATH:/data/gpadmin/gpdb/greenplum/lib/hadoop/gphd-2.0.2-gnet-1.2.0.0.jar:/data/gpadmin/workspace/tincrepo/main/mpp/gpdb/tests/package/gphdfs/maptest.jar -Dhdfshost=sdw1.dh.greenplum.com -Ddatanodeport=8020 -Djobtrackerhost=sdw1.dh.greenplum.com -Djobtrackerport=8020  -DcompressionType=none javaclasses/TestHadoopIntegration mapreduce Mapreduce_mapper_GPDB_INOUT /extwrite/date /mapreduce/date_gpdb/ 
14/08/15 13:10:20 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 13:10:21 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/08/15 13:10:22 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
14/08/15 13:10:22 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 323 for gpadmin on 192.168.2.100:8020
14/08/15 13:10:22 INFO security.TokenCache: Got dt for hdfs://sdw1.dh.greenplum.com:8020; Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 323 for gpadmin)
14/08/15 13:10:22 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/08/15 13:10:22 INFO input.FileInputFormat: Total input paths to process : 2
14/08/15 13:10:22 INFO mapreduce.JobSubmitter: number of splits:2
14/08/15 13:10:22 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/08/15 13:10:22 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/08/15 13:10:22 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 13:10:22 INFO Configuration.deprecation: mapred.job.reduce.memory.mb is deprecated. Instead, use mapreduce.reduce.memory.mb
14/08/15 13:10:22 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/08/15 13:10:22 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/08/15 13:10:22 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/08/15 13:10:22 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
14/08/15 13:10:22 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/08/15 13:10:22 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/08/15 13:10:22 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/08/15 13:10:22 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/08/15 13:10:22 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/08/15 13:10:22 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/08/15 13:10:22 INFO Configuration.deprecation: mapred.job.map.memory.mb is deprecated. Instead, use mapreduce.map.memory.mb
14/08/15 13:10:22 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/08/15 13:10:23 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1408131000469_0053
14/08/15 13:10:23 INFO mapreduce.JobSubmitter: Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 323 for gpadmin)
14/08/15 13:10:23 INFO impl.YarnClientImpl: Submitted application application_1408131000469_0053 to ResourceManager at /0.0.0.0:8032
14/08/15 13:10:23 INFO mapreduce.Job: The url to track the job: http://0.0.0.0:9999/proxy/application_1408131000469_0053/
14/08/15 13:10:23 INFO mapreduce.Job: Running job: job_1408131000469_0053
14/08/15 13:10:31 INFO mapreduce.Job: Job job_1408131000469_0053 running in uber mode : false
14/08/15 13:10:31 INFO mapreduce.Job:  map 0% reduce 0%
14/08/15 13:10:37 INFO mapreduce.Job:  map 100% reduce 0%
14/08/15 13:10:42 INFO mapreduce.Job:  map 100% reduce 100%
14/08/15 13:10:42 INFO mapreduce.Job: Job job_1408131000469_0053 completed successfully
14/08/15 13:10:43 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=1015006
		FILE: Number of bytes written=2284235
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1050444
		HDFS: Number of bytes written=1050086
		HDFS: Number of read operations=11
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=23253
		Total time spent by all reduces in occupied slots (ms)=10077
	Map-Reduce Framework
		Map input records=5000
		Map output records=5000
		Map output bytes=1000000
		Map output materialized bytes=1015012
		Input split bytes=272
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=1015012
		Reduce input records=5000
		Reduce output records=5000
		Spilled Records=10000
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=71
		CPU time spent (ms)=5720
		Physical memory (bytes) snapshot=1795977216
		Virtual memory (bytes) snapshot=8288530432
		Total committed heap usage (bytes)=2242641920
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1050172
	File Output Format Counters 
		Bytes Written=1050086
\!export HADOOP_HOME=/usr/lib/gphd/hadoop/; source /data/gpadmin/gpdb/greenplum/lib/hadoop/hadoop_env.sh; java -cp .:$CLASSPATH:/data/gpadmin/gpdb/greenplum/lib/hadoop/gphd-2.0.2-gnet-1.2.0.0.jar:/data/gpadmin/workspace/tincrepo/main/mpp/gpdb/tests/package/gphdfs/maptest.jar -Dhdfshost=sdw1.dh.greenplum.com -Ddatanodeport=8020 -Djobtrackerhost=sdw1.dh.greenplum.com -Djobtrackerport=8020  -DcompressionType=none javaclasses/TestHadoopIntegration mapred Mapred_mapper_GPDB_INOUT /extwrite/date /mapred/date_gpdb/
14/08/15 13:10:44 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 13:10:44 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
14/08/15 13:10:44 INFO Configuration.deprecation: mapred.job.map.memory.mb is deprecated. Instead, use mapreduce.map.memory.mb
14/08/15 13:10:44 INFO Configuration.deprecation: mapred.job.reduce.memory.mb is deprecated. Instead, use mapreduce.reduce.memory.mb
14/08/15 13:10:44 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/08/15 13:10:45 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
14/08/15 13:10:45 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
14/08/15 13:10:46 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 324 for gpadmin on 192.168.2.100:8020
14/08/15 13:10:46 INFO security.TokenCache: Got dt for hdfs://sdw1.dh.greenplum.com:8020; Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 324 for gpadmin)
14/08/15 13:10:46 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/08/15 13:10:46 INFO mapred.FileInputFormat: Total input paths to process : 2
14/08/15 13:10:46 INFO mapreduce.JobSubmitter: number of splits:2
14/08/15 13:10:46 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/08/15 13:10:46 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/08/15 13:10:46 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 13:10:46 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/08/15 13:10:46 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/08/15 13:10:46 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
14/08/15 13:10:46 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/08/15 13:10:46 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/08/15 13:10:46 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/08/15 13:10:46 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/08/15 13:10:46 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/08/15 13:10:46 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1408131000469_0054
14/08/15 13:10:46 INFO mapreduce.JobSubmitter: Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 324 for gpadmin)
14/08/15 13:10:46 INFO impl.YarnClientImpl: Submitted application application_1408131000469_0054 to ResourceManager at /0.0.0.0:8032
14/08/15 13:10:47 INFO mapreduce.Job: The url to track the job: http://0.0.0.0:9999/proxy/application_1408131000469_0054/
14/08/15 13:10:47 INFO mapreduce.Job: Running job: job_1408131000469_0054
14/08/15 13:10:58 INFO mapreduce.Job: Job job_1408131000469_0054 running in uber mode : false
14/08/15 13:10:58 INFO mapreduce.Job:  map 0% reduce 0%
14/08/15 13:11:03 INFO mapreduce.Job:  map 100% reduce 0%
14/08/15 13:11:10 INFO mapreduce.Job:  map 100% reduce 100%
14/08/15 13:11:11 INFO mapreduce.Job: Job job_1408131000469_0054 completed successfully
14/08/15 13:11:11 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=1015006
		FILE: Number of bytes written=2283743
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1050418
		HDFS: Number of bytes written=1050086
		HDFS: Number of read operations=11
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=23313
		Total time spent by all reduces in occupied slots (ms)=12183
	Map-Reduce Framework
		Map input records=5000
		Map output records=5000
		Map output bytes=1000000
		Map output materialized bytes=1015012
		Input split bytes=246
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=1015012
		Reduce input records=5000
		Reduce output records=5000
		Spilled Records=10000
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=75
		CPU time spent (ms)=6850
		Physical memory (bytes) snapshot=1798123520
		Virtual memory (bytes) snapshot=8288530432
		Total committed heap usage (bytes)=2242641920
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1050172
	File Output Format Counters 
		Bytes Written=1050086
\!export HADOOP_HOME=/usr/lib/gphd/hadoop/; source /data/gpadmin/gpdb/greenplum/lib/hadoop/hadoop_env.sh; java -cp .:$CLASSPATH:/data/gpadmin/gpdb/greenplum/lib/hadoop/gphd-2.0.2-gnet-1.2.0.0.jar:/data/gpadmin/workspace/tincrepo/main/mpp/gpdb/tests/package/gphdfs/maptest.jar -Dhdfshost=sdw1.dh.greenplum.com -Ddatanodeport=8020 -Djobtrackerhost=sdw1.dh.greenplum.com -Djobtrackerport=8020  -DcompressionType=block javaclasses/TestHadoopIntegration mapreduce Mapreduce_mapper_GPDB_INOUT /extwrite/date /mapreduce/blockcomp/date_gpdb/
14/08/15 13:11:12 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 13:11:13 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/08/15 13:11:14 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
14/08/15 13:11:14 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 325 for gpadmin on 192.168.2.100:8020
14/08/15 13:11:14 INFO security.TokenCache: Got dt for hdfs://sdw1.dh.greenplum.com:8020; Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 325 for gpadmin)
14/08/15 13:11:14 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/08/15 13:11:14 INFO input.FileInputFormat: Total input paths to process : 2
14/08/15 13:11:14 INFO mapreduce.JobSubmitter: number of splits:2
14/08/15 13:11:15 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/08/15 13:11:15 INFO Configuration.deprecation: mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress
14/08/15 13:11:15 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/08/15 13:11:15 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 13:11:15 INFO Configuration.deprecation: mapred.job.reduce.memory.mb is deprecated. Instead, use mapreduce.reduce.memory.mb
14/08/15 13:11:15 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/08/15 13:11:15 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/08/15 13:11:15 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/08/15 13:11:15 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
14/08/15 13:11:15 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/08/15 13:11:15 INFO Configuration.deprecation: mapred.output.compression.type is deprecated. Instead, use mapreduce.output.fileoutputformat.compress.type
14/08/15 13:11:15 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/08/15 13:11:15 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/08/15 13:11:15 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/08/15 13:11:15 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/08/15 13:11:15 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/08/15 13:11:15 INFO Configuration.deprecation: mapred.job.map.memory.mb is deprecated. Instead, use mapreduce.map.memory.mb
14/08/15 13:11:15 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/08/15 13:11:15 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1408131000469_0055
14/08/15 13:11:15 INFO mapreduce.JobSubmitter: Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 325 for gpadmin)
14/08/15 13:11:15 INFO impl.YarnClientImpl: Submitted application application_1408131000469_0055 to ResourceManager at /0.0.0.0:8032
14/08/15 13:11:15 INFO mapreduce.Job: The url to track the job: http://0.0.0.0:9999/proxy/application_1408131000469_0055/
14/08/15 13:11:15 INFO mapreduce.Job: Running job: job_1408131000469_0055
14/08/15 13:11:25 INFO mapreduce.Job: Job job_1408131000469_0055 running in uber mode : false
14/08/15 13:11:25 INFO mapreduce.Job:  map 0% reduce 0%
14/08/15 13:11:31 INFO mapreduce.Job:  map 100% reduce 0%
14/08/15 13:11:38 INFO mapreduce.Job:  map 100% reduce 100%
14/08/15 13:11:38 INFO mapreduce.Job: Job job_1408131000469_0055 completed successfully
14/08/15 13:11:38 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=1015006
		FILE: Number of bytes written=2284241
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1050444
		HDFS: Number of bytes written=88758
		HDFS: Number of read operations=11
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=22386
		Total time spent by all reduces in occupied slots (ms)=12144
	Map-Reduce Framework
		Map input records=5000
		Map output records=5000
		Map output bytes=1000000
		Map output materialized bytes=1015012
		Input split bytes=272
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=1015012
		Reduce input records=5000
		Reduce output records=5000
		Spilled Records=10000
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=66
		CPU time spent (ms)=5800
		Physical memory (bytes) snapshot=1791197184
		Virtual memory (bytes) snapshot=8290717696
		Total committed heap usage (bytes)=2242641920
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1050172
	File Output Format Counters 
		Bytes Written=88758
\!export HADOOP_HOME=/usr/lib/gphd/hadoop/; source /data/gpadmin/gpdb/greenplum/lib/hadoop/hadoop_env.sh; java -cp .:$CLASSPATH:/data/gpadmin/gpdb/greenplum/lib/hadoop/gphd-2.0.2-gnet-1.2.0.0.jar:/data/gpadmin/workspace/tincrepo/main/mpp/gpdb/tests/package/gphdfs/maptest.jar -Dhdfshost=sdw1.dh.greenplum.com -Ddatanodeport=8020 -Djobtrackerhost=sdw1.dh.greenplum.com -Djobtrackerport=8020  -DcompressionType=block javaclasses/TestHadoopIntegration mapred Mapred_mapper_GPDB_INOUT /extwrite/date /mapred/blockcomp/date_gpdb/
14/08/15 13:11:39 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 13:11:39 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
14/08/15 13:11:39 INFO Configuration.deprecation: mapred.job.map.memory.mb is deprecated. Instead, use mapreduce.map.memory.mb
14/08/15 13:11:39 INFO Configuration.deprecation: mapred.job.reduce.memory.mb is deprecated. Instead, use mapreduce.reduce.memory.mb
14/08/15 13:11:39 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/08/15 13:11:40 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
14/08/15 13:11:40 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
14/08/15 13:11:41 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 326 for gpadmin on 192.168.2.100:8020
14/08/15 13:11:41 INFO security.TokenCache: Got dt for hdfs://sdw1.dh.greenplum.com:8020; Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 326 for gpadmin)
14/08/15 13:11:41 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/08/15 13:11:41 INFO mapred.FileInputFormat: Total input paths to process : 2
14/08/15 13:11:41 INFO mapreduce.JobSubmitter: number of splits:2
14/08/15 13:11:41 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/08/15 13:11:41 INFO Configuration.deprecation: mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress
14/08/15 13:11:41 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/08/15 13:11:41 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 13:11:41 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/08/15 13:11:41 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/08/15 13:11:41 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
14/08/15 13:11:41 INFO Configuration.deprecation: mapred.output.compression.type is deprecated. Instead, use mapreduce.output.fileoutputformat.compress.type
14/08/15 13:11:41 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/08/15 13:11:41 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/08/15 13:11:41 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/08/15 13:11:41 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/08/15 13:11:41 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/08/15 13:11:41 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1408131000469_0056
14/08/15 13:11:41 INFO mapreduce.JobSubmitter: Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 326 for gpadmin)
14/08/15 13:11:42 INFO impl.YarnClientImpl: Submitted application application_1408131000469_0056 to ResourceManager at /0.0.0.0:8032
14/08/15 13:11:42 INFO mapreduce.Job: The url to track the job: http://0.0.0.0:9999/proxy/application_1408131000469_0056/
14/08/15 13:11:42 INFO mapreduce.Job: Running job: job_1408131000469_0056
14/08/15 13:11:53 INFO mapreduce.Job: Job job_1408131000469_0056 running in uber mode : false
14/08/15 13:11:53 INFO mapreduce.Job:  map 0% reduce 0%
14/08/15 13:11:58 INFO mapreduce.Job:  map 100% reduce 0%
14/08/15 13:12:05 INFO mapreduce.Job:  map 100% reduce 100%
14/08/15 13:12:05 INFO mapreduce.Job: Job job_1408131000469_0056 completed successfully
14/08/15 13:12:05 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=1015006
		FILE: Number of bytes written=2283749
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1050418
		HDFS: Number of bytes written=88656
		HDFS: Number of read operations=11
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=22599
		Total time spent by all reduces in occupied slots (ms)=12111
	Map-Reduce Framework
		Map input records=5000
		Map output records=5000
		Map output bytes=1000000
		Map output materialized bytes=1015012
		Input split bytes=246
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=1015012
		Reduce input records=5000
		Reduce output records=5000
		Spilled Records=10000
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=66
		CPU time spent (ms)=6040
		Physical memory (bytes) snapshot=1789087744
		Virtual memory (bytes) snapshot=8290717696
		Total committed heap usage (bytes)=2242641920
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1050172
	File Output Format Counters 
		Bytes Written=88656
\!export HADOOP_HOME=/usr/lib/gphd/hadoop/; source /data/gpadmin/gpdb/greenplum/lib/hadoop/hadoop_env.sh; java -cp .:$CLASSPATH:/data/gpadmin/gpdb/greenplum/lib/hadoop/gphd-2.0.2-gnet-1.2.0.0.jar:/data/gpadmin/workspace/tincrepo/main/mpp/gpdb/tests/package/gphdfs/maptest.jar -Dhdfshost=sdw1.dh.greenplum.com -Ddatanodeport=8020 -Djobtrackerhost=sdw1.dh.greenplum.com -Djobtrackerport=8020  -DcompressionType=record javaclasses/TestHadoopIntegration mapreduce Mapreduce_mapper_GPDB_INOUT /extwrite/date /mapreduce/recordcomp/date_gpdb/
14/08/15 13:12:06 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 13:12:07 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/08/15 13:12:08 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
14/08/15 13:12:08 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 327 for gpadmin on 192.168.2.100:8020
14/08/15 13:12:08 INFO security.TokenCache: Got dt for hdfs://sdw1.dh.greenplum.com:8020; Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 327 for gpadmin)
14/08/15 13:12:08 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/08/15 13:12:08 INFO input.FileInputFormat: Total input paths to process : 2
14/08/15 13:12:08 INFO mapreduce.JobSubmitter: number of splits:2
14/08/15 13:12:08 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/08/15 13:12:08 INFO Configuration.deprecation: mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress
14/08/15 13:12:08 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/08/15 13:12:08 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 13:12:08 INFO Configuration.deprecation: mapred.job.reduce.memory.mb is deprecated. Instead, use mapreduce.reduce.memory.mb
14/08/15 13:12:08 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/08/15 13:12:08 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/08/15 13:12:08 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/08/15 13:12:08 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
14/08/15 13:12:08 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/08/15 13:12:08 INFO Configuration.deprecation: mapred.output.compression.type is deprecated. Instead, use mapreduce.output.fileoutputformat.compress.type
14/08/15 13:12:08 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/08/15 13:12:08 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/08/15 13:12:08 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/08/15 13:12:08 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/08/15 13:12:08 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/08/15 13:12:08 INFO Configuration.deprecation: mapred.job.map.memory.mb is deprecated. Instead, use mapreduce.map.memory.mb
14/08/15 13:12:08 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/08/15 13:12:09 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1408131000469_0057
14/08/15 13:12:09 INFO mapreduce.JobSubmitter: Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 327 for gpadmin)
14/08/15 13:12:09 INFO impl.YarnClientImpl: Submitted application application_1408131000469_0057 to ResourceManager at /0.0.0.0:8032
14/08/15 13:12:09 INFO mapreduce.Job: The url to track the job: http://0.0.0.0:9999/proxy/application_1408131000469_0057/
14/08/15 13:12:09 INFO mapreduce.Job: Running job: job_1408131000469_0057
14/08/15 13:12:20 INFO mapreduce.Job: Job job_1408131000469_0057 running in uber mode : false
14/08/15 13:12:20 INFO mapreduce.Job:  map 0% reduce 0%
14/08/15 13:12:25 INFO mapreduce.Job:  map 100% reduce 0%
14/08/15 13:12:32 INFO mapreduce.Job:  map 100% reduce 100%
14/08/15 13:12:33 INFO mapreduce.Job: Job job_1408131000469_0057 completed successfully
14/08/15 13:12:33 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=1015006
		FILE: Number of bytes written=2284247
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1050444
		HDFS: Number of bytes written=436482
		HDFS: Number of read operations=11
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=23643
		Total time spent by all reduces in occupied slots (ms)=11949
	Map-Reduce Framework
		Map input records=5000
		Map output records=5000
		Map output bytes=1000000
		Map output materialized bytes=1015012
		Input split bytes=272
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=1015012
		Reduce input records=5000
		Reduce output records=5000
		Spilled Records=10000
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=68
		CPU time spent (ms)=6020
		Physical memory (bytes) snapshot=1808961536
		Virtual memory (bytes) snapshot=8290717696
		Total committed heap usage (bytes)=2242641920
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1050172
	File Output Format Counters 
		Bytes Written=436482
\!export HADOOP_HOME=/usr/lib/gphd/hadoop/; source /data/gpadmin/gpdb/greenplum/lib/hadoop/hadoop_env.sh; java -cp .:$CLASSPATH:/data/gpadmin/gpdb/greenplum/lib/hadoop/gphd-2.0.2-gnet-1.2.0.0.jar:/data/gpadmin/workspace/tincrepo/main/mpp/gpdb/tests/package/gphdfs/maptest.jar -Dhdfshost=sdw1.dh.greenplum.com -Ddatanodeport=8020 -Djobtrackerhost=sdw1.dh.greenplum.com -Djobtrackerport=8020  -DcompressionType=record javaclasses/TestHadoopIntegration mapred Mapred_mapper_GPDB_INOUT /extwrite/date /mapred/recordcomp/date_gpdb/
14/08/15 13:12:34 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 13:12:34 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
14/08/15 13:12:34 INFO Configuration.deprecation: mapred.job.map.memory.mb is deprecated. Instead, use mapreduce.map.memory.mb
14/08/15 13:12:34 INFO Configuration.deprecation: mapred.job.reduce.memory.mb is deprecated. Instead, use mapreduce.reduce.memory.mb
14/08/15 13:12:35 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/08/15 13:12:36 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
14/08/15 13:12:36 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
14/08/15 13:12:36 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 328 for gpadmin on 192.168.2.100:8020
14/08/15 13:12:36 INFO security.TokenCache: Got dt for hdfs://sdw1.dh.greenplum.com:8020; Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 328 for gpadmin)
14/08/15 13:12:36 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/08/15 13:12:37 INFO mapred.FileInputFormat: Total input paths to process : 2
14/08/15 13:12:37 INFO mapreduce.JobSubmitter: number of splits:2
14/08/15 13:12:37 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/08/15 13:12:37 INFO Configuration.deprecation: mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress
14/08/15 13:12:37 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/08/15 13:12:37 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 13:12:37 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/08/15 13:12:37 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/08/15 13:12:37 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
14/08/15 13:12:37 INFO Configuration.deprecation: mapred.output.compression.type is deprecated. Instead, use mapreduce.output.fileoutputformat.compress.type
14/08/15 13:12:37 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/08/15 13:12:37 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/08/15 13:12:37 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/08/15 13:12:37 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/08/15 13:12:37 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/08/15 13:12:37 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1408131000469_0058
14/08/15 13:12:37 INFO mapreduce.JobSubmitter: Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 328 for gpadmin)
14/08/15 13:12:37 INFO impl.YarnClientImpl: Submitted application application_1408131000469_0058 to ResourceManager at /0.0.0.0:8032
14/08/15 13:12:37 INFO mapreduce.Job: The url to track the job: http://0.0.0.0:9999/proxy/application_1408131000469_0058/
14/08/15 13:12:37 INFO mapreduce.Job: Running job: job_1408131000469_0058
14/08/15 13:12:47 INFO mapreduce.Job: Job job_1408131000469_0058 running in uber mode : false
14/08/15 13:12:47 INFO mapreduce.Job:  map 0% reduce 0%
14/08/15 13:12:54 INFO mapreduce.Job:  map 100% reduce 0%
14/08/15 13:13:00 INFO mapreduce.Job:  map 100% reduce 100%
14/08/15 13:13:00 INFO mapreduce.Job: Job job_1408131000469_0058 completed successfully
14/08/15 13:13:00 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=1015006
		FILE: Number of bytes written=2283755
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1050418
		HDFS: Number of bytes written=436482
		HDFS: Number of read operations=11
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=21396
		Total time spent by all reduces in occupied slots (ms)=11736
	Map-Reduce Framework
		Map input records=5000
		Map output records=5000
		Map output bytes=1000000
		Map output materialized bytes=1015012
		Input split bytes=246
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=1015012
		Reduce input records=5000
		Reduce output records=5000
		Spilled Records=10000
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=79
		CPU time spent (ms)=5710
		Physical memory (bytes) snapshot=1792593920
		Virtual memory (bytes) snapshot=8290717696
		Total committed heap usage (bytes)=2242641920
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1050172
	File Output Format Counters 
		Bytes Written=436482
create readable external table date_verification_mapreduce(like date_heap) location ('gphdfs://sdw1.dh.greenplum.com:8020/mapreduce/date_gpdb/')format 'custom' (formatter='gphdfs_import');
CREATE EXTERNAL TABLE
create readable external table date_verification_mapred(like date_heap) location ('gphdfs://sdw1.dh.greenplum.com:8020/mapred/date_gpdb/')format 'custom' (formatter='gphdfs_import');
CREATE EXTERNAL TABLE
create readable external table date_verification_blockcomp_mapreduce(like date_heap) location ('gphdfs://sdw1.dh.greenplum.com:8020/mapreduce/blockcomp/date_gpdb/')format 'custom' (formatter='gphdfs_import');
CREATE EXTERNAL TABLE
create readable external table date_verification_blockcomp_mapred(like date_heap) location ('gphdfs://sdw1.dh.greenplum.com:8020/mapred/blockcomp/date_gpdb/')format 'custom' (formatter='gphdfs_import');
CREATE EXTERNAL TABLE
create readable external table date_verification_recordcomp_mapreduce(like date_heap) location ('gphdfs://sdw1.dh.greenplum.com:8020/mapreduce/recordcomp/date_gpdb/')format 'custom' (formatter='gphdfs_import');
CREATE EXTERNAL TABLE
create readable external table date_verification_recordcomp_mapred(like date_heap) location ('gphdfs://sdw1.dh.greenplum.com:8020/mapred/recordcomp/date_gpdb/')format 'custom' (formatter='gphdfs_import');
CREATE EXTERNAL TABLE
(select * from date_verification_mapreduce except select * from date_verification_mapred) union (select * from date_verification_mapred except select * from date_verification_mapreduce);
 datatype_date | x_date | col1_date | col2_date | col3_date | col4_date | col5_date | col6_date | col7_date | nullcol_date 
---------------+--------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+--------------
(0 rows)

(select * from date_verification_blockcomp_mapreduce except select * from date_verification_blockcomp_mapred) union (select * from date_verification_blockcomp_mapred except select * from date_verification_blockcomp_mapreduce);
 datatype_date | x_date | col1_date | col2_date | col3_date | col4_date | col5_date | col6_date | col7_date | nullcol_date 
---------------+--------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+--------------
(0 rows)

(select * from date_verification_recordcomp_mapreduce except select * from date_verification_recordcomp_mapred) union (select * from date_verification_recordcomp_mapred except select * from date_verification_recordcomp_mapreduce);
 datatype_date | x_date | col1_date | col2_date | col3_date | col4_date | col5_date | col6_date | col7_date | nullcol_date 
---------------+--------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+--------------
(0 rows)

(select * from date_verification_recordcomp_mapreduce except select * from date_verification_blockcomp_mapreduce) union (select * from date_verification_blockcomp_mapreduce except select * from date_verification_recordcomp_mapreduce);
 datatype_date | x_date | col1_date | col2_date | col3_date | col4_date | col5_date | col6_date | col7_date | nullcol_date 
---------------+--------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+--------------
(0 rows)

(select * from date_verification_recordcomp_mapreduce except select * from date_verification_mapreduce) union (select * from date_verification_mapreduce except select * from date_verification_recordcomp_mapreduce);
 datatype_date | x_date | col1_date | col2_date | col3_date | col4_date | col5_date | col6_date | col7_date | nullcol_date 
---------------+--------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+--------------
(0 rows)

(select * from date_verification_recordcomp_mapreduce except select * from date_heap) union (select * from date_heap except select * from date_verification_recordcomp_mapreduce);
 datatype_date | x_date | col1_date | col2_date | col3_date | col4_date | col5_date | col6_date | col7_date | nullcol_date 
---------------+--------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+--------------
(0 rows)


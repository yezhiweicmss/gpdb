-- start_ignore
-- end_ignore
\echo --start_ignore
--start_ignore
drop external table bigint_heap;
DROP EXTERNAL TABLE
drop external table bigint_writehdfs;
DROP EXTERNAL TABLE
drop external table bigint_verification_mapreduce;
DROP EXTERNAL TABLE
drop external table bigint_verification_mapred;
DROP EXTERNAL TABLE
drop external table bigint_verification_blockcomp_mapreduce;
DROP EXTERNAL TABLE
drop external table bigint_verification_blockcomp_mapred;
DROP EXTERNAL TABLE
drop external table bigint_verification_recordcomp_mapreduce;
DROP EXTERNAL TABLE
drop external table bigint_verification_recordcomp_mapred;
DROP EXTERNAL TABLE
\echo --end_ignore
--end_ignore
create readable external table bigint_heap(
datatype_bigint varchar,xcount_bigint bigint, max_bigint bigint, min_bigint bigint, x_bigint bigint, reverse_bigint bigint, increment_bigint bigint, nullcol_bigint bigint
--datatype_bigint varchar,xcount_bigint bigint, max_bigint bigint, min_bigint bigint, x_bigint bigint, reverse_bigint bigint, increment_bigint bigint
) location ('gpfdist://sdw1.dh.greenplum.com:8080/bigint.txt')format 'TEXT';
CREATE EXTERNAL TABLE
create writable external table bigint_writehdfs(like bigint_heap) location ('gphdfs://sdw1.dh.greenplum.com:8020/extwrite/bigint')format 'custom' (formatter='gphdfs_export');
psql:/path/sql_file:1: NOTICE:  Table doesn't have 'distributed by' clause, defaulting to distribution columns from LIKE table
CREATE EXTERNAL TABLE
insert into bigint_writehdfs select * from bigint_heap;
INSERT 0 5000
\!export HADOOP_HOME=/usr/lib/gphd/hadoop/; source /data/gpadmin/gpdb/greenplum/lib/hadoop/hadoop_env.sh; java -cp .:$CLASSPATH:/data/gpadmin/gpdb/greenplum/lib/hadoop/gphd-2.0.2-gnet-1.2.0.0.jar:/data/gpadmin/workspace/tincrepo/main/mpp/gpdb/tests/package/gphdfs/maptest.jar -Dhdfshost=sdw1.dh.greenplum.com -Ddatanodeport=8020 -Djobtrackerhost=sdw1.dh.greenplum.com -Djobtrackerport=8020  -DcompressionType=none javaclasses/TestHadoopIntegration mapreduce Mapreduce_mapper_GPDB_INOUT /extwrite/bigint /mapreduce/bigint_gpdb/ 
14/08/15 12:57:09 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 12:57:09 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/08/15 12:57:10 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
14/08/15 12:57:11 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 151 for gpadmin on 192.168.2.100:8020
14/08/15 12:57:11 INFO security.TokenCache: Got dt for hdfs://sdw1.dh.greenplum.com:8020; Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 151 for gpadmin)
14/08/15 12:57:11 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/08/15 12:57:11 INFO input.FileInputFormat: Total input paths to process : 2
14/08/15 12:57:11 INFO mapreduce.JobSubmitter: number of splits:2
14/08/15 12:57:11 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/08/15 12:57:11 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/08/15 12:57:11 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 12:57:11 INFO Configuration.deprecation: mapred.job.reduce.memory.mb is deprecated. Instead, use mapreduce.reduce.memory.mb
14/08/15 12:57:11 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/08/15 12:57:11 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/08/15 12:57:11 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/08/15 12:57:11 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
14/08/15 12:57:11 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/08/15 12:57:11 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/08/15 12:57:11 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/08/15 12:57:11 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/08/15 12:57:11 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/08/15 12:57:11 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/08/15 12:57:11 INFO Configuration.deprecation: mapred.job.map.memory.mb is deprecated. Instead, use mapreduce.map.memory.mb
14/08/15 12:57:11 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/08/15 12:57:11 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1408131000469_0035
14/08/15 12:57:11 INFO mapreduce.JobSubmitter: Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 151 for gpadmin)
14/08/15 12:57:12 INFO impl.YarnClientImpl: Submitted application application_1408131000469_0035 to ResourceManager at /0.0.0.0:8032
14/08/15 12:57:12 INFO mapreduce.Job: The url to track the job: http://0.0.0.0:9999/proxy/application_1408131000469_0035/
14/08/15 12:57:12 INFO mapreduce.Job: Running job: job_1408131000469_0035
14/08/15 12:57:21 INFO mapreduce.Job: Job job_1408131000469_0035 running in uber mode : false
14/08/15 12:57:21 INFO mapreduce.Job:  map 0% reduce 0%
14/08/15 12:57:26 INFO mapreduce.Job:  map 100% reduce 0%
14/08/15 12:57:32 INFO mapreduce.Job:  map 100% reduce 100%
14/08/15 12:57:32 INFO mapreduce.Job: Job job_1408131000469_0035 completed successfully
14/08/15 12:57:32 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=650006
		FILE: Number of bytes written=1554247
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=687128
		HDFS: Number of bytes written=686766
		HDFS: Number of read operations=11
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=21603
		Total time spent by all reduces in occupied slots (ms)=11547
	Map-Reduce Framework
		Map input records=5000
		Map output records=5000
		Map output bytes=640000
		Map output materialized bytes=650012
		Input split bytes=276
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=650012
		Reduce input records=5000
		Reduce output records=5000
		Spilled Records=10000
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=65
		CPU time spent (ms)=4990
		Physical memory (bytes) snapshot=1788116992
		Virtual memory (bytes) snapshot=8288530432
		Total committed heap usage (bytes)=2242641920
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=686852
	File Output Format Counters 
		Bytes Written=686766
\!export HADOOP_HOME=/usr/lib/gphd/hadoop/; source /data/gpadmin/gpdb/greenplum/lib/hadoop/hadoop_env.sh; java -cp .:$CLASSPATH:/data/gpadmin/gpdb/greenplum/lib/hadoop/gphd-2.0.2-gnet-1.2.0.0.jar:/data/gpadmin/workspace/tincrepo/main/mpp/gpdb/tests/package/gphdfs/maptest.jar -Dhdfshost=sdw1.dh.greenplum.com -Ddatanodeport=8020 -Djobtrackerhost=sdw1.dh.greenplum.com -Djobtrackerport=8020  -DcompressionType=none javaclasses/TestHadoopIntegration mapred Mapred_mapper_GPDB_INOUT /extwrite/bigint /mapred/bigint_gpdb/
14/08/15 12:57:33 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 12:57:33 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
14/08/15 12:57:33 INFO Configuration.deprecation: mapred.job.map.memory.mb is deprecated. Instead, use mapreduce.map.memory.mb
14/08/15 12:57:33 INFO Configuration.deprecation: mapred.job.reduce.memory.mb is deprecated. Instead, use mapreduce.reduce.memory.mb
14/08/15 12:57:34 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/08/15 12:57:35 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
14/08/15 12:57:35 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
14/08/15 12:57:35 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 152 for gpadmin on 192.168.2.100:8020
14/08/15 12:57:35 INFO security.TokenCache: Got dt for hdfs://sdw1.dh.greenplum.com:8020; Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 152 for gpadmin)
14/08/15 12:57:35 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/08/15 12:57:35 INFO mapred.FileInputFormat: Total input paths to process : 2
14/08/15 12:57:36 INFO mapreduce.JobSubmitter: number of splits:2
14/08/15 12:57:36 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/08/15 12:57:36 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/08/15 12:57:36 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 12:57:36 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/08/15 12:57:36 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/08/15 12:57:36 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
14/08/15 12:57:36 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/08/15 12:57:36 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/08/15 12:57:36 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/08/15 12:57:36 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/08/15 12:57:36 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/08/15 12:57:36 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1408131000469_0036
14/08/15 12:57:36 INFO mapreduce.JobSubmitter: Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 152 for gpadmin)
14/08/15 12:57:36 INFO impl.YarnClientImpl: Submitted application application_1408131000469_0036 to ResourceManager at /0.0.0.0:8032
14/08/15 12:57:36 INFO mapreduce.Job: The url to track the job: http://0.0.0.0:9999/proxy/application_1408131000469_0036/
14/08/15 12:57:36 INFO mapreduce.Job: Running job: job_1408131000469_0036
14/08/15 12:57:47 INFO mapreduce.Job: Job job_1408131000469_0036 running in uber mode : false
14/08/15 12:57:47 INFO mapreduce.Job:  map 0% reduce 0%
14/08/15 12:57:53 INFO mapreduce.Job:  map 100% reduce 0%
14/08/15 12:58:00 INFO mapreduce.Job:  map 100% reduce 100%
14/08/15 12:58:00 INFO mapreduce.Job: Job job_1408131000469_0036 completed successfully
14/08/15 12:58:01 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=650006
		FILE: Number of bytes written=1553755
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=687102
		HDFS: Number of bytes written=686766
		HDFS: Number of read operations=11
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=23445
		Total time spent by all reduces in occupied slots (ms)=10941
	Map-Reduce Framework
		Map input records=5000
		Map output records=5000
		Map output bytes=640000
		Map output materialized bytes=650012
		Input split bytes=250
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=650012
		Reduce input records=5000
		Reduce output records=5000
		Spilled Records=10000
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=64
		CPU time spent (ms)=5570
		Physical memory (bytes) snapshot=1797812224
		Virtual memory (bytes) snapshot=8288530432
		Total committed heap usage (bytes)=2242641920
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=686852
	File Output Format Counters 
		Bytes Written=686766
\!export HADOOP_HOME=/usr/lib/gphd/hadoop/; source /data/gpadmin/gpdb/greenplum/lib/hadoop/hadoop_env.sh; java -cp .:$CLASSPATH:/data/gpadmin/gpdb/greenplum/lib/hadoop/gphd-2.0.2-gnet-1.2.0.0.jar:/data/gpadmin/workspace/tincrepo/main/mpp/gpdb/tests/package/gphdfs/maptest.jar -Dhdfshost=sdw1.dh.greenplum.com -Ddatanodeport=8020 -Djobtrackerhost=sdw1.dh.greenplum.com -Djobtrackerport=8020  -DcompressionType=block javaclasses/TestHadoopIntegration mapreduce Mapreduce_mapper_GPDB_INOUT /extwrite/bigint /mapreduce/blockcomp/bigint_gpdb/
14/08/15 12:58:01 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 12:58:02 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/08/15 12:58:03 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
14/08/15 12:58:03 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 153 for gpadmin on 192.168.2.100:8020
14/08/15 12:58:04 INFO security.TokenCache: Got dt for hdfs://sdw1.dh.greenplum.com:8020; Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 153 for gpadmin)
14/08/15 12:58:04 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/08/15 12:58:04 INFO input.FileInputFormat: Total input paths to process : 2
14/08/15 12:58:04 INFO mapreduce.JobSubmitter: number of splits:2
14/08/15 12:58:04 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/08/15 12:58:04 INFO Configuration.deprecation: mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress
14/08/15 12:58:04 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/08/15 12:58:04 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 12:58:04 INFO Configuration.deprecation: mapred.job.reduce.memory.mb is deprecated. Instead, use mapreduce.reduce.memory.mb
14/08/15 12:58:04 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/08/15 12:58:04 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/08/15 12:58:04 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/08/15 12:58:04 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
14/08/15 12:58:04 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/08/15 12:58:04 INFO Configuration.deprecation: mapred.output.compression.type is deprecated. Instead, use mapreduce.output.fileoutputformat.compress.type
14/08/15 12:58:04 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/08/15 12:58:04 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/08/15 12:58:04 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/08/15 12:58:04 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/08/15 12:58:04 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/08/15 12:58:04 INFO Configuration.deprecation: mapred.job.map.memory.mb is deprecated. Instead, use mapreduce.map.memory.mb
14/08/15 12:58:04 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/08/15 12:58:04 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1408131000469_0037
14/08/15 12:58:04 INFO mapreduce.JobSubmitter: Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 153 for gpadmin)
14/08/15 12:58:04 INFO impl.YarnClientImpl: Submitted application application_1408131000469_0037 to ResourceManager at /0.0.0.0:8032
14/08/15 12:58:04 INFO mapreduce.Job: The url to track the job: http://0.0.0.0:9999/proxy/application_1408131000469_0037/
14/08/15 12:58:04 INFO mapreduce.Job: Running job: job_1408131000469_0037
14/08/15 12:58:16 INFO mapreduce.Job: Job job_1408131000469_0037 running in uber mode : false
14/08/15 12:58:16 INFO mapreduce.Job:  map 0% reduce 0%
14/08/15 12:58:21 INFO mapreduce.Job:  map 100% reduce 0%
14/08/15 12:58:28 INFO mapreduce.Job:  map 100% reduce 100%
14/08/15 12:58:28 INFO mapreduce.Job: Job job_1408131000469_0037 completed successfully
14/08/15 12:58:28 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=650006
		FILE: Number of bytes written=1554253
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=687128
		HDFS: Number of bytes written=53315
		HDFS: Number of read operations=11
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=21381
		Total time spent by all reduces in occupied slots (ms)=11904
	Map-Reduce Framework
		Map input records=5000
		Map output records=5000
		Map output bytes=640000
		Map output materialized bytes=650012
		Input split bytes=276
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=650012
		Reduce input records=5000
		Reduce output records=5000
		Spilled Records=10000
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=43
		CPU time spent (ms)=5070
		Physical memory (bytes) snapshot=1808203776
		Virtual memory (bytes) snapshot=8291004416
		Total committed heap usage (bytes)=2242641920
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=686852
	File Output Format Counters 
		Bytes Written=53315
\!export HADOOP_HOME=/usr/lib/gphd/hadoop/; source /data/gpadmin/gpdb/greenplum/lib/hadoop/hadoop_env.sh; java -cp .:$CLASSPATH:/data/gpadmin/gpdb/greenplum/lib/hadoop/gphd-2.0.2-gnet-1.2.0.0.jar:/data/gpadmin/workspace/tincrepo/main/mpp/gpdb/tests/package/gphdfs/maptest.jar -Dhdfshost=sdw1.dh.greenplum.com -Ddatanodeport=8020 -Djobtrackerhost=sdw1.dh.greenplum.com -Djobtrackerport=8020  -DcompressionType=block javaclasses/TestHadoopIntegration mapred Mapred_mapper_GPDB_INOUT /extwrite/bigint /mapred/blockcomp/bigint_gpdb/
14/08/15 12:58:29 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 12:58:29 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
14/08/15 12:58:29 INFO Configuration.deprecation: mapred.job.map.memory.mb is deprecated. Instead, use mapreduce.map.memory.mb
14/08/15 12:58:29 INFO Configuration.deprecation: mapred.job.reduce.memory.mb is deprecated. Instead, use mapreduce.reduce.memory.mb
14/08/15 12:58:29 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/08/15 12:58:30 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
14/08/15 12:58:30 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
14/08/15 12:58:31 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 154 for gpadmin on 192.168.2.100:8020
14/08/15 12:58:31 INFO security.TokenCache: Got dt for hdfs://sdw1.dh.greenplum.com:8020; Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 154 for gpadmin)
14/08/15 12:58:31 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/08/15 12:58:31 INFO mapred.FileInputFormat: Total input paths to process : 2
14/08/15 12:58:31 INFO mapreduce.JobSubmitter: number of splits:2
14/08/15 12:58:31 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/08/15 12:58:31 INFO Configuration.deprecation: mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress
14/08/15 12:58:31 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/08/15 12:58:31 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 12:58:31 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/08/15 12:58:31 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/08/15 12:58:31 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
14/08/15 12:58:31 INFO Configuration.deprecation: mapred.output.compression.type is deprecated. Instead, use mapreduce.output.fileoutputformat.compress.type
14/08/15 12:58:31 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/08/15 12:58:31 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/08/15 12:58:31 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/08/15 12:58:31 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/08/15 12:58:31 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/08/15 12:58:31 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1408131000469_0038
14/08/15 12:58:31 INFO mapreduce.JobSubmitter: Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 154 for gpadmin)
14/08/15 12:58:32 INFO impl.YarnClientImpl: Submitted application application_1408131000469_0038 to ResourceManager at /0.0.0.0:8032
14/08/15 12:58:32 INFO mapreduce.Job: The url to track the job: http://0.0.0.0:9999/proxy/application_1408131000469_0038/
14/08/15 12:58:32 INFO mapreduce.Job: Running job: job_1408131000469_0038
14/08/15 12:58:42 INFO mapreduce.Job: Job job_1408131000469_0038 running in uber mode : false
14/08/15 12:58:42 INFO mapreduce.Job:  map 0% reduce 0%
14/08/15 12:58:48 INFO mapreduce.Job:  map 100% reduce 0%
14/08/15 12:58:55 INFO mapreduce.Job:  map 100% reduce 100%
14/08/15 12:58:55 INFO mapreduce.Job: Job job_1408131000469_0038 completed successfully
14/08/15 12:58:55 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=650006
		FILE: Number of bytes written=1553761
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=687102
		HDFS: Number of bytes written=53315
		HDFS: Number of read operations=11
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=23778
		Total time spent by all reduces in occupied slots (ms)=11946
	Map-Reduce Framework
		Map input records=5000
		Map output records=5000
		Map output bytes=640000
		Map output materialized bytes=650012
		Input split bytes=250
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=650012
		Reduce input records=5000
		Reduce output records=5000
		Spilled Records=10000
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=77
		CPU time spent (ms)=5720
		Physical memory (bytes) snapshot=1820991488
		Virtual memory (bytes) snapshot=8290717696
		Total committed heap usage (bytes)=2242641920
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=686852
	File Output Format Counters 
		Bytes Written=53315
\!export HADOOP_HOME=/usr/lib/gphd/hadoop/; source /data/gpadmin/gpdb/greenplum/lib/hadoop/hadoop_env.sh; java -cp .:$CLASSPATH:/data/gpadmin/gpdb/greenplum/lib/hadoop/gphd-2.0.2-gnet-1.2.0.0.jar:/data/gpadmin/workspace/tincrepo/main/mpp/gpdb/tests/package/gphdfs/maptest.jar -Dhdfshost=sdw1.dh.greenplum.com -Ddatanodeport=8020 -Djobtrackerhost=sdw1.dh.greenplum.com -Djobtrackerport=8020  -DcompressionType=record javaclasses/TestHadoopIntegration mapreduce Mapreduce_mapper_GPDB_INOUT /extwrite/bigint /mapreduce/recordcomp/bigint_gpdb/
14/08/15 12:58:56 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 12:58:57 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/08/15 12:58:58 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
14/08/15 12:58:58 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 155 for gpadmin on 192.168.2.100:8020
14/08/15 12:58:58 INFO security.TokenCache: Got dt for hdfs://sdw1.dh.greenplum.com:8020; Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 155 for gpadmin)
14/08/15 12:58:58 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/08/15 12:58:59 INFO input.FileInputFormat: Total input paths to process : 2
14/08/15 12:58:59 INFO mapreduce.JobSubmitter: number of splits:2
14/08/15 12:58:59 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/08/15 12:58:59 INFO Configuration.deprecation: mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress
14/08/15 12:58:59 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/08/15 12:58:59 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 12:58:59 INFO Configuration.deprecation: mapred.job.reduce.memory.mb is deprecated. Instead, use mapreduce.reduce.memory.mb
14/08/15 12:58:59 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/08/15 12:58:59 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/08/15 12:58:59 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/08/15 12:58:59 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
14/08/15 12:58:59 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/08/15 12:58:59 INFO Configuration.deprecation: mapred.output.compression.type is deprecated. Instead, use mapreduce.output.fileoutputformat.compress.type
14/08/15 12:58:59 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/08/15 12:58:59 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/08/15 12:58:59 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/08/15 12:58:59 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/08/15 12:58:59 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/08/15 12:58:59 INFO Configuration.deprecation: mapred.job.map.memory.mb is deprecated. Instead, use mapreduce.map.memory.mb
14/08/15 12:58:59 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/08/15 12:58:59 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1408131000469_0039
14/08/15 12:58:59 INFO mapreduce.JobSubmitter: Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 155 for gpadmin)
14/08/15 12:58:59 INFO impl.YarnClientImpl: Submitted application application_1408131000469_0039 to ResourceManager at /0.0.0.0:8032
14/08/15 12:58:59 INFO mapreduce.Job: The url to track the job: http://0.0.0.0:9999/proxy/application_1408131000469_0039/
14/08/15 12:58:59 INFO mapreduce.Job: Running job: job_1408131000469_0039
14/08/15 12:59:10 INFO mapreduce.Job: Job job_1408131000469_0039 running in uber mode : false
14/08/15 12:59:10 INFO mapreduce.Job:  map 0% reduce 0%
14/08/15 12:59:17 INFO mapreduce.Job:  map 100% reduce 0%
14/08/15 12:59:23 INFO mapreduce.Job:  map 100% reduce 100%
14/08/15 12:59:23 INFO mapreduce.Job: Job job_1408131000469_0039 completed successfully
14/08/15 12:59:23 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=650006
		FILE: Number of bytes written=1554259
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=687128
		HDFS: Number of bytes written=322752
		HDFS: Number of read operations=11
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=21597
		Total time spent by all reduces in occupied slots (ms)=12141
	Map-Reduce Framework
		Map input records=5000
		Map output records=5000
		Map output bytes=640000
		Map output materialized bytes=650012
		Input split bytes=276
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=650012
		Reduce input records=5000
		Reduce output records=5000
		Spilled Records=10000
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=111
		CPU time spent (ms)=5590
		Physical memory (bytes) snapshot=1850257408
		Virtual memory (bytes) snapshot=8290717696
		Total committed heap usage (bytes)=2242641920
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=686852
	File Output Format Counters 
		Bytes Written=322752
\!export HADOOP_HOME=/usr/lib/gphd/hadoop/; source /data/gpadmin/gpdb/greenplum/lib/hadoop/hadoop_env.sh; java -cp .:$CLASSPATH:/data/gpadmin/gpdb/greenplum/lib/hadoop/gphd-2.0.2-gnet-1.2.0.0.jar:/data/gpadmin/workspace/tincrepo/main/mpp/gpdb/tests/package/gphdfs/maptest.jar -Dhdfshost=sdw1.dh.greenplum.com -Ddatanodeport=8020 -Djobtrackerhost=sdw1.dh.greenplum.com -Djobtrackerport=8020  -DcompressionType=record javaclasses/TestHadoopIntegration mapred Mapred_mapper_GPDB_INOUT /extwrite/bigint /mapred/recordcomp/bigint_gpdb/
14/08/15 12:59:24 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 12:59:24 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
14/08/15 12:59:24 INFO Configuration.deprecation: mapred.job.map.memory.mb is deprecated. Instead, use mapreduce.map.memory.mb
14/08/15 12:59:24 INFO Configuration.deprecation: mapred.job.reduce.memory.mb is deprecated. Instead, use mapreduce.reduce.memory.mb
14/08/15 12:59:24 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/08/15 12:59:25 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
14/08/15 12:59:25 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
14/08/15 12:59:26 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 156 for gpadmin on 192.168.2.100:8020
14/08/15 12:59:26 INFO security.TokenCache: Got dt for hdfs://sdw1.dh.greenplum.com:8020; Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 156 for gpadmin)
14/08/15 12:59:26 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/08/15 12:59:26 INFO mapred.FileInputFormat: Total input paths to process : 2
14/08/15 12:59:26 INFO mapreduce.JobSubmitter: number of splits:2
14/08/15 12:59:26 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/08/15 12:59:26 INFO Configuration.deprecation: mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress
14/08/15 12:59:26 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/08/15 12:59:26 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
14/08/15 12:59:26 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/08/15 12:59:26 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/08/15 12:59:26 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
14/08/15 12:59:26 INFO Configuration.deprecation: mapred.output.compression.type is deprecated. Instead, use mapreduce.output.fileoutputformat.compress.type
14/08/15 12:59:26 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/08/15 12:59:26 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/08/15 12:59:26 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/08/15 12:59:26 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/08/15 12:59:26 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/08/15 12:59:26 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1408131000469_0040
14/08/15 12:59:26 INFO mapreduce.JobSubmitter: Kind: HDFS_DELEGATION_TOKEN, Service: 192.168.2.100:8020, Ident: (HDFS_DELEGATION_TOKEN token 156 for gpadmin)
14/08/15 12:59:26 INFO impl.YarnClientImpl: Submitted application application_1408131000469_0040 to ResourceManager at /0.0.0.0:8032
14/08/15 12:59:27 INFO mapreduce.Job: The url to track the job: http://0.0.0.0:9999/proxy/application_1408131000469_0040/
14/08/15 12:59:27 INFO mapreduce.Job: Running job: job_1408131000469_0040
14/08/15 12:59:38 INFO mapreduce.Job: Job job_1408131000469_0040 running in uber mode : false
14/08/15 12:59:38 INFO mapreduce.Job:  map 0% reduce 0%
14/08/15 12:59:43 INFO mapreduce.Job:  map 100% reduce 0%
14/08/15 12:59:50 INFO mapreduce.Job:  map 100% reduce 100%
14/08/15 12:59:50 INFO mapreduce.Job: Job job_1408131000469_0040 completed successfully
14/08/15 12:59:50 INFO mapreduce.Job: Counters: 43
	File System Counters
		FILE: Number of bytes read=650006
		FILE: Number of bytes written=1553767
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=687102
		HDFS: Number of bytes written=322752
		HDFS: Number of read operations=11
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=20406
		Total time spent by all reduces in occupied slots (ms)=11958
	Map-Reduce Framework
		Map input records=5000
		Map output records=5000
		Map output bytes=640000
		Map output materialized bytes=650012
		Input split bytes=250
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=650012
		Reduce input records=5000
		Reduce output records=5000
		Spilled Records=10000
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=65
		CPU time spent (ms)=5080
		Physical memory (bytes) snapshot=1793929216
		Virtual memory (bytes) snapshot=8290717696
		Total committed heap usage (bytes)=2242641920
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=686852
	File Output Format Counters 
		Bytes Written=322752
create readable external table bigint_verification_mapreduce(like bigint_heap) location ('gphdfs://sdw1.dh.greenplum.com:8020/mapreduce/bigint_gpdb/')format 'custom' (formatter='gphdfs_import');
CREATE EXTERNAL TABLE
create readable external table bigint_verification_mapred(like bigint_heap) location ('gphdfs://sdw1.dh.greenplum.com:8020/mapred/bigint_gpdb/')format 'custom' (formatter='gphdfs_import');
CREATE EXTERNAL TABLE
create readable external table bigint_verification_blockcomp_mapreduce(like bigint_heap) location ('gphdfs://sdw1.dh.greenplum.com:8020/mapreduce/blockcomp/bigint_gpdb/')format 'custom' (formatter='gphdfs_import');
CREATE EXTERNAL TABLE
create readable external table bigint_verification_blockcomp_mapred(like bigint_heap) location ('gphdfs://sdw1.dh.greenplum.com:8020/mapred/blockcomp/bigint_gpdb/')format 'custom' (formatter='gphdfs_import');
CREATE EXTERNAL TABLE
create readable external table bigint_verification_recordcomp_mapreduce(like bigint_heap) location ('gphdfs://sdw1.dh.greenplum.com:8020/mapreduce/recordcomp/bigint_gpdb/')format 'custom' (formatter='gphdfs_import');
CREATE EXTERNAL TABLE
create readable external table bigint_verification_recordcomp_mapred(like bigint_heap) location ('gphdfs://sdw1.dh.greenplum.com:8020/mapred/recordcomp/bigint_gpdb/')format 'custom' (formatter='gphdfs_import');
CREATE EXTERNAL TABLE
(select * from bigint_verification_mapreduce except select * from bigint_verification_mapred) union (select * from bigint_verification_mapred except select * from bigint_verification_mapreduce);
 datatype_bigint | xcount_bigint | max_bigint | min_bigint | x_bigint | reverse_bigint | increment_bigint | nullcol_bigint 
-----------------+---------------+------------+------------+----------+----------------+------------------+----------------
(0 rows)

(select * from bigint_verification_blockcomp_mapreduce except select * from bigint_verification_blockcomp_mapred) union (select * from bigint_verification_blockcomp_mapred except select * from bigint_verification_blockcomp_mapreduce);
 datatype_bigint | xcount_bigint | max_bigint | min_bigint | x_bigint | reverse_bigint | increment_bigint | nullcol_bigint 
-----------------+---------------+------------+------------+----------+----------------+------------------+----------------
(0 rows)

(select * from bigint_verification_recordcomp_mapreduce except select * from bigint_verification_recordcomp_mapred) union (select * from bigint_verification_recordcomp_mapred except select * from bigint_verification_recordcomp_mapreduce);
 datatype_bigint | xcount_bigint | max_bigint | min_bigint | x_bigint | reverse_bigint | increment_bigint | nullcol_bigint 
-----------------+---------------+------------+------------+----------+----------------+------------------+----------------
(0 rows)

(select * from bigint_verification_recordcomp_mapreduce except select * from bigint_verification_blockcomp_mapreduce) union (select * from bigint_verification_blockcomp_mapreduce except select * from bigint_verification_recordcomp_mapreduce);
 datatype_bigint | xcount_bigint | max_bigint | min_bigint | x_bigint | reverse_bigint | increment_bigint | nullcol_bigint 
-----------------+---------------+------------+------------+----------+----------------+------------------+----------------
(0 rows)

(select * from bigint_verification_recordcomp_mapreduce except select * from bigint_verification_mapreduce) union (select * from bigint_verification_mapreduce except select * from bigint_verification_recordcomp_mapreduce);
 datatype_bigint | xcount_bigint | max_bigint | min_bigint | x_bigint | reverse_bigint | increment_bigint | nullcol_bigint 
-----------------+---------------+------------+------------+----------+----------------+------------------+----------------
(0 rows)

(select * from bigint_verification_recordcomp_mapreduce except select * from bigint_heap) union (select * from bigint_heap except select * from bigint_verification_recordcomp_mapreduce);
 datatype_bigint | xcount_bigint | max_bigint | min_bigint | x_bigint | reverse_bigint | increment_bigint | nullcol_bigint 
-----------------+---------------+------------+------------+----------+----------------+------------------+----------------
(0 rows)

